{"type": "objectives", "question": "Linear regression models are trained by minimizing the mean squared error between predictions and true values.", "options": ["True", "False"], "correct_index": 0, "explanation": "The standard training objective for linear regression is to minimize the mean squared error, which measures the average squared difference between predicted and actual values.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "objectives", "question": "In binary classification, a higher recall always indicates a better model than one with higher precision.", "options": ["True", "False"], "correct_index": 1, "explanation": "Recall measures the proportion of actual positives correctly identified, while precision measures the proportion of predicted positives that are correct. Depending on the problem, higher precision may be more valuable; thus higher recall does not always mean a better model.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which hyperparameter determines how many samples are processed before the model’s internal parameters are updated?", "options": ["Learning rate", "Epoch", "Batch size", "Regularization strength"], "correct_index": 2, "explanation": "The batch size defines the number of training examples used to compute a single gradient update. Smaller batches lead to noisier updates, while larger batches use more memory.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In the context of logistic regression, what does the sigmoid function output?", "options": ["A probability between 0 and 1", "A binary class label directly", "The gradient of the loss function", "The learning rate for the next iteration"], "correct_index": 0, "explanation": "The sigmoid function maps any real‑valued input to a value in the (0,1) interval, which can be interpreted as the probability of belonging to the positive class.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"]}
{"type": "mcq", "question": "Which metric is calculated as TP ÷ (TP + FP) ?", "options": ["Accuracy", "Recall", "Precision", "F1‑score"], "correct_index": 2, "explanation": "Precision focuses on the correctness of positive predictions and is defined as true positives divided by the sum of true and false positives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"]}
{"type": "mcq", "question": "When accessing a value in a Python dictionary, which syntax is correct?", "options": ["dict[‘key’]", "dict.key", "dict(‘key’)", "dict{‘key’}"], "correct_index": 0, "explanation": "Dictionary values are accessed using square brackets with the key inside quotes (or the appropriate key type). Attribute‑style access is not supported for dictionaries.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 7 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following best describes the role of an epoch in training a model?", "options": ["The number of samples processed in one gradient update", "The total number of passes through the entire training dataset", "The step size taken during gradient descent", "The regularization term added to the loss"], "correct_index": 1, "explanation": "An epoch represents a full iteration over the whole training set. Multiple epochs allow the model to see the data repeatedly and refine its parameters.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which statement about the learning rate is correct?", "options": ["A larger learning rate always speeds up convergence without risk.", "A too‑large learning rate can cause the loss to diverge.", "The learning rate determines how many epochs are needed.", "Learning rate is only relevant for batch size, not for gradient descent."], "correct_index": 1, "explanation": "If the learning rate is too high, updates may overshoot minima, causing the loss to increase or diverge. Proper tuning balances speed and stability.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "fill_blank", "question": "In binary classification, the formula for recall is __________.", "options": [], "correct_index": 0, "explanation": "Recall (also called sensitivity) measures the proportion of actual positive cases that are correctly identified, calculated as true positives divided by the sum of true positives and false negatives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"], "answer": "TP / (TP + FN)"}
{"type": "fill_blank", "question": "The term __________ refers to the number of times the learning algorithm iterates over the entire training dataset.", "options": [], "correct_index": 0, "explanation": "An epoch is a full pass through the training data. Multiple epochs are often required for the model to converge.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"], "answer": "epoch"}
{"type": "fill_blank", "question": "The logistic regression decision boundary is determined by the __________ function applied to the linear combination of inputs.", "options": [], "correct_index": 0, "explanation": "Logistic regression uses the sigmoid (logistic) function to convert a linear score into a probability, which is then thresholded to produce class predictions.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"], "answer": "sigmoid"}
{"type": "coding", "question": "Implement a Python function `compute_precision` that takes two integers, `tp` (true positives) and `fp` (false positives), and returns the precision as a float. If the denominator is zero, return 0.0.", "options": [], "correct_index": 0, "explanation": "Precision is defined as TP ÷ (TP + FP). Handling a zero denominator avoids division‑by‑zero errors, which is a common edge case in metric implementations.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"], "prompt": "Write the function according to the specification.", "starter_code": "", "tests": ["Verify `compute_precision(5, 0)` returns 1.0.", "Verify `compute_precision(0, 5)` returns 0.0.", "Verify `compute_precision(3, 2)` returns 0.6."]}
{"type": "general", "question": "Which of the following is a key advantage of using a validation set during model development?", "options": ["It reduces the size of the training data.", "It provides an unbiased estimate of model performance on unseen data.", "It guarantees the model will achieve 100% accuracy.", "It eliminates the need for hyperparameter tuning."], "correct_index": 1, "explanation": "A validation set is held out from training and used to assess how the model generalizes, helping to detect overfitting and guide hyperparameter choices.", "citations": []}
{"type": "general", "question": "In supervised learning, the term “label” refers to:", "options": ["The input features fed to the model.", "The algorithm used to train the model.", "The target output that the model aims to predict.", "The loss function minimized during training."], "correct_index": 2, "explanation": "Labels are the ground‑truth outputs associated with each training example; the model learns to map inputs to these labels.", "citations": []}
{"type": "objectives", "question": "Linear regression and logistic regression are both used for classification tasks.", "options": ["True", "False"], "correct_index": 1, "explanation": "Linear regression is used for predicting continuous values, while logistic regression is used for binary classification. (Track context discussing linear regression and logistic regression as separate topics)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 6 CLASS 1 - Recording Transcript.txt"]}
{"type": "objectives", "question": "Precision is calculated as true positives divided by (true positives + false positives).", "options": ["True", "False"], "correct_index": 0, "explanation": "The definition of precision was explained when discussing evaluation metrics. (Track context describing precision as TP / (TP + FP))", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In machine learning, an “epoch” refers to:", "options": ["The number of features in the dataset", "One full pass through the entire training set", "The learning rate used during training", "The size of each mini‑batch"], "correct_index": 1, "explanation": "The term epoch was mentioned when reviewing fundamental terminologies such as epoch, learning rate, and batch size. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following best describes “batch size”?", "options": ["The total number of epochs to run", "The number of samples processed before the model’s internal parameters are updated", "The proportion of data reserved for testing", "The regularization strength"], "correct_index": 1, "explanation": "Batch size was listed among the fundamentals, indicating how many samples are used per update step. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "A higher learning rate typically:", "options": ["Makes training converge faster but may overshoot minima", "Guarantees higher accuracy", "Reduces the number of epochs needed without risk", "Has no effect on model performance"], "correct_index": 0, "explanation": "Learning rate was discussed as a key hyper‑parameter influencing convergence speed and stability. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which evaluation metric measures the proportion of all predictions that are correct?", "options": ["Precision", "Recall", "Accuracy", "F1‑score"], "correct_index": 2, "explanation": "Accuracy was defined as the sum of all correct predictions divided by total predictions. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Precision focuses on:", "options": ["True positives over all actual positives", "True positives over all predicted positives", "True negatives over all actual negatives", "False positives over all predictions"], "correct_index": 1, "explanation": "Precision deals with TP / (TP + FP) as described in the discussion of evaluation metrics. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Recall focuses on:", "options": ["True positives over all predicted positives", "True positives over all actual positives", "True negatives over all actual negatives", "False negatives over all predictions"], "correct_index": 1, "explanation": "Recall (also called true positive rate) is TP / (TP + FN). (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which software was mentioned as a “not free” tool used for the no‑code portion of the class?", "options": ["Python", "R", "MATLAB", "TensorFlow"], "correct_index": 2, "explanation": "The instructor noted that MATLAB is not free but will be used for the no‑code sessions. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1 - Recording Transcript (1).txt"]}
{"type": "fill_blank", "question": "In a confusion matrix, the number of false negatives is denoted as ___.", "options": [], "correct_index": 0, "explanation": "The discussion of confusion matrix components listed false negatives (FN) alongside TP, FP, and TN. (Track context)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "FN"}
{"type": "fill_blank", "question": "The typical train‑test split mentioned is ___ percent training and ___ percent testing.", "options": [], "correct_index": 0, "explanation": "The style hint explicitly said “split your data sets into 8020”. (Style hint)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "80% training and 20% testing"}
{"type": "fill_blank", "question": "Five‑fold cross‑validation means the data is divided into ___ folds.", "options": [], "correct_index": 0, "explanation": "The instruction to use “five‑four cross validation” (interpreted as five‑fold) was given for model evaluation. (Style hint)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "five"}
{"type": "coding", "question": "Implement a simple logistic regression predictor that takes a list of feature values, computes the sigmoid of the linear combination (assume weight = 0.5 and bias = ‑0.1), and returns 1 if the probability ≥ 0.5 else 0.", "options": [], "correct_index": 0, "explanation": "This task reinforces understanding of logistic regression inference, using the sigmoid function and a decision threshold. (Track context on logistic regression demonstration)", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 6 CLASS 1 - Recording Transcript.txt"], "prompt": "Write a function `predict_logistic(features)` that returns the binary class.", "starter_code": "", "tests": ["Input: [2, 4] → Expected output: 1", "Input: [-1, -3] → Expected output: 0"]}
{"type": "general", "question": "Which of the following best describes artificial intelligence?", "options": ["A set of hardware devices that compute faster than humans", "The study of algorithms that enable machines to perform tasks that normally require human intelligence", "A programming language for data analysis", "A type of computer virus"], "correct_index": 1, "explanation": "General definition of AI as the field concerned with enabling machines to exhibit intelligent behavior.", "citations": []}
{"type": "general", "question": "In supervised learning, the training data consists of:", "options": ["Only input features without any labels", "Input features paired with correct output labels", "Random noise generated by the algorithm", "Unlabeled data that the model must cluster"], "correct_index": 1, "explanation": "Supervised learning relies on labeled examples to train models.", "citations": []}
{"type": "objectives", "question": "Linear regression was discussed in the previous class as a fundamental concept.", "options": ["True", "False"], "correct_index": 0, "explanation": "The transcript notes that the last class covered linear regression among other fundamentals【data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "objectives", "question": "The term \"epoch\" refers to the number of features used in a model.", "options": ["True", "False"], "correct_index": 1, "explanation": "An epoch is a full pass through the training data, not the number of features【data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following hyper‑parameters controls how large a step the optimizer takes during training?", "options": ["Batch size", "Learning rate", "Epoch", "Precision"], "correct_index": 1, "explanation": "The learning rate determines the step size of weight updates in gradient‑based training【data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In binary classification, which metric is calculated as TP / (TP + FP)?", "options": ["Recall", "Accuracy", "Precision", "F1‑score"], "correct_index": 2, "explanation": "Precision equals true positives divided by the sum of true and false positives, as explained in the lecture on classification【data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "What does the dictionary syntax `car[\"year\"]` retrieve?", "options": ["The index of the car in a list", "The value associated with the key \"year\"", "The entire car object", "The function named year"], "correct_index": 1, "explanation": "Using square brackets with a string key accesses the corresponding value in a Python dictionary【data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following best describes recall?", "options": ["TP / (TP + FP)", "TP / (TP + FN)", "(TP + TN) / All samples", "FN / (TP + FN)"], "correct_index": 1, "explanation": "Recall (also called true positive rate) is TP divided by the sum of TP and FN【data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which platform was mentioned as not being free but used for “no‑code” work?", "options": ["Teachable Machine", "MATLAB", "Scikit‑learn", "TensorFlow"], "correct_index": 1, "explanation": "The instructor said MATLAB is not free but will be used for the no‑code portion of the class【data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1 - Recording Transcript (1).txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1 - Recording Transcript (1).txt"]}
{"type": "fill_blank", "question": "The term __________ refers to the number of training examples processed before the model’s internal parameters are updated.", "options": [], "correct_index": 0, "explanation": "Batch size is defined as the count of samples used in one forward/backward pass before updating weights【data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"], "answer": "batch size"}
{"type": "fill_blank", "question": "In logistic regression, the output is transformed by the __________ function to map predictions to probabilities between 0 and 1.", "options": [], "correct_index": 0, "explanation": "Logistic regression uses the sigmoid (logistic) function to convert linear outputs into probability estimates【data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "sigmoid"}
{"type": "fill_blank", "question": "The metric that combines precision and recall into a single score is called the __________.", "options": [], "correct_index": 0, "explanation": "The F1‑score is the harmonic mean of precision and recall, providing a balance between the two【data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "F1‑score"}
{"type": "coding", "question": "Write a Python function `accuracy(tp, fp, fn, tn)` that returns the classification accuracy as a float.", "options": [], "correct_index": 0, "explanation": "Accuracy = (TP + TN) / (TP + FP + FN + TN). The test cases verify correct computation and edge‑case handling【data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt】.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "prompt": "Implement the function according to the standard definition of accuracy.", "starter_code": "|\n  def accuracy(tp, fp, fn, tn):\n      # TODO: compute accuracy\n      pass", "tests": ["accuracy(50, 10, 5, 35) should return 0.85", "accuracy(0, 0, 0, 0) should return 0.0 (handle division by zero)"]}
{"type": "general", "question": "Which of the following is NOT a valid question type in this exam specification?", "options": ["objectives", "fill_blank", "essay", "coding"], "correct_index": 2, "explanation": "The provided format lists objectives, mcq, fill_blank, coding, and general; “essay” is not among them.", "citations": ["(no specific source; derived from exam instructions)"]}
{"type": "general", "question": "According to the exam instructions, how many multiple‑choice items should be created for the track section?", "options": ["5", "7", "10", "12"], "correct_index": 1, "explanation": "The target counts specify 7 multiple‑choice questions for the track portion.", "citations": []}
{"type": "objectives", "question": "Linear regression is a classification algorithm.", "options": ["True", "False", "Not enough information", "Both true and false"], "correct_index": 1, "explanation": "The track context states that the class discussed linear regression as a fundamental concept, distinct from classification tasks such as logistic regression. Linear regression predicts continuous values, not class labels.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "objectives", "question": "In binary classification, precision is calculated as TP / (TP + FP).", "options": ["True", "False", "Depends on the dataset", "Only for multi‑class problems"], "correct_index": 0, "explanation": "The transcript (Week 4 Class 1) explains that precision deals with true positives divided by the sum of true positives and false positives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"]}
{"type": "mcq", "question": "Which of the following hyper‑parameters controls how much the model’s weights are updated during each iteration?", "options": ["Epoch", "Learning rate", "Batch size", "Cross‑validation folds"], "correct_index": 1, "explanation": "The track notes list “learning rate” as a fundamental terminology that determines the step size of weight updates.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "When splitting a dataset for model evaluation, the recommended ratio mentioned in the course is:", "options": ["70% train / 30% test", "60% train / 40% test", "80% train / 20% test", "90% train / 10% test"], "correct_index": 2, "explanation": "The style hint about logistic regression says “you split your data sets into 80/20.”", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"]}
{"type": "mcq", "question": "Five‑fold cross‑validation means that the data is divided into how many parts?", "options": ["2", "5", "10", "20"], "correct_index": 1, "explanation": "The transcript explicitly mentions “five‑four cross validation” (interpreted as five‑fold cross validation) as a required practice.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which metric is defined as TP / (TP + FN)?", "options": ["Accuracy", "Precision", "Recall", "F1‑score"], "correct_index": 2, "explanation": "The discussion on recall states it is true positives divided by the sum of true positives and false negatives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"]}
{"type": "mcq", "question": "According to the course requirements, the model must achieve at least what accuracy on the test sample?", "options": ["75%", "80%", "81%", "85%"], "correct_index": 2, "explanation": "The style hint explicitly requires “at least 81% accuracy on test sample.”", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"]}
{"type": "mcq", "question": "In the context of dictionaries in Python, which of the following is a valid key type?", "options": ["List", "Dictionary", "Integer", "Set"], "correct_index": 2, "explanation": "The transcript explains that dictionary keys must be immutable, giving integers as an example.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3  - Recording Transcript.txt"]}
{"type": "fill_blank", "question": "The term that describes one complete pass through the entire training dataset is called a _______.", "options": [], "correct_index": 0, "explanation": "The class reviewed fundamental terminologies and listed “epoch” as the term for a full pass over the data.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"], "answer": "epoch"}
{"type": "fill_blank", "question": "The metric that measures the proportion of correctly predicted instances among all predictions is _______.", "options": [], "correct_index": 0, "explanation": "Accuracy is defined in the transcript as “the sum of everything” correctly predicted divided by total predictions.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"], "answer": "accuracy"}
{"type": "fill_blank", "question": "In logistic regression for binary classification, the output is transformed using the _______ function.", "options": [], "correct_index": 0, "explanation": "Logistic regression converts linear scores to probabilities via the sigmoid (logistic) function, as demonstrated in the class.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"], "answer": "sigmoid"}
{"type": "coding", "question": "Implement a Python function `predict_logistic` that takes a NumPy array of feature vectors `X`, a weight vector `w`, and a bias `b`, computes the sigmoid of the linear combination, and returns a binary array of predictions (1 if probability ≥ 0.5, else 0).", "options": [], "correct_index": 0, "explanation": "The coding task reinforces the logistic regression prediction pipeline discussed in the class, including linear combination, sigmoid activation, and thresholding.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2  - Recording Transcript.txt"], "prompt": "", "starter_code": "", "tests": ["Verify that for X=[[0,0]], w=[0,0], b=0 the prediction is [1] (since sigmoid(0)=0.5).", "Verify that for X=[[2, -1]], w=[1, 2], b=-3 the prediction matches manual calculation."]}
{"type": "general", "question": "Which of the following is NOT a type of machine learning?", "options": ["Supervised learning", "Unsupervised learning", "Reinforcement learning", "Deterministic programming"], "correct_index": 3, "explanation": "Deterministic programming is not a machine‑learning paradigm; the other three are standard categories.", "citations": []}
{"type": "general", "question": "In the context of AI, the term “model” most closely refers to:", "options": ["The raw dataset", "The algorithm’s source code", "The learned parameters after training", "The hardware used for computation"], "correct_index": 2, "explanation": "A model encapsulates the parameters (weights, biases, etc.) that have been learned from data.", "citations": []}
{"type": "objectives", "question": "Linear regression and logistic regression were both covered in the previous class.", "options": ["True", "False"], "correct_index": 0, "explanation": "The transcript notes that the last class briefly discussed linear regression and then moved on to logistic regression for classification tasks.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt", "data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "objectives", "question": "In binary classification, recall is calculated as true positives divided by (true positives + false negatives).", "options": ["True", "False"], "correct_index": 0, "explanation": "The recordings describe recall (positive rate) as true positive divided by the sum of true positives and false negatives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt", "data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3  - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following is NOT a fundamental term mentioned when discussing regression models?", "options": ["Epoch", "Learning rate", "Batch size", "Confusion matrix"], "correct_index": 3, "explanation": "Epoch, learning rate, and batch size were listed as fundamentals; confusion matrix relates to classification evaluation, not regression fundamentals.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "According to the instructor, what dataset split ratio should be used for training and testing a logistic regression model?", "options": ["70% train / 30% test", "80% train / 20% test", "60% train / 40% test", "90% train / 10% test"], "correct_index": 1, "explanation": "The style hint explicitly states an 80/20 split for training and testing.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which validation technique was recommended for assessing model performance?", "options": ["Hold‑out validation", "Leave‑one‑out cross‑validation", "5‑fold cross‑validation", "Bootstrap resampling"], "correct_index": 2, "explanation": "The instructor mentioned using five‑fold cross‑validation.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "What minimum test‑set accuracy should be achieved on the logistic regression model?", "options": ["70%", "75%", "81%", "85%"], "correct_index": 2, "explanation": "The style hint requires at least 81% accuracy on the test sample.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In the context of binary classification, which metric focuses on the proportion of correctly identified positive instances among all predicted positives?", "options": ["Accuracy", "Precision", "Recall", "F1‑score"], "correct_index": 1, "explanation": "Precision is defined as true positives divided by (true positives + false positives), as described in the transcript.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt", "data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3  - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which programming environment was highlighted as the primary tool for “no‑code” demonstrations?", "options": ["Python", "R", "MATLAB", "JavaScript"], "correct_index": 2, "explanation": "The instructor noted that MATLAB would be used for the no‑code portion of the course.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"]}
{"type": "fill_blank", "question": "The term that describes the ratio of true positives to the sum of true positives and false positives is called _______.", "options": [], "correct_index": 0, "explanation": "Precision is defined as TP / (TP + FP) in the lecture.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "precision"}
{"type": "fill_blank", "question": "In logistic regression, the decision boundary is determined by the _______ function.", "options": [], "correct_index": 0, "explanation": "Logistic regression uses the sigmoid (logistic) function to map linear combinations to probabilities.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "sigmoid"}
{"type": "fill_blank", "question": "A dataset split of 80% training and 20% testing is commonly referred to as an _______ split.", "options": [], "correct_index": 0, "explanation": "The instructor explicitly instructed using an 80/20 split for training and testing.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "80/20"}
{"type": "coding", "question": "Implement a Python function `evaluate_metrics(y_true, y_pred)` that returns a dictionary with accuracy, precision, and recall for binary classification.", "options": [], "correct_index": 0, "explanation": "The task assesses understanding of the core evaluation metrics discussed (accuracy, precision, recall) and requires translating the definitions into code.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt", "data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3  - Recording Transcript.txt"], "prompt": "|\n  def evaluate_metrics(y_true, y_pred):\n      \"\"\"\n      Compute accuracy, precision, and recall.", "starter_code": "|\n  # You may use sklearn.metrics if you wish, but implement the calculations manually.\n  pass", "tests": ["Verify that evaluate_metrics([0,1,1,0],[0,1,0,0]) returns accuracy = 0.75, precision = 0.5, recall = 0.5."]}
{"type": "general", "question": "According to the style hints, where should students commit their code for the assignment?", "options": ["On a private GitHub repository", "On a public GitHub repository", "In a zip file uploaded to the LMS", "Directly in the Google Colab notebook"], "correct_index": 1, "explanation": "The style hint instructs students to commit their work to a public GitHub repository and submit the link.", "citations": ["(No specific source; derived from STYLE HINTS)"]}
{"type": "general", "question": "The style hints suggest using which machine‑learning algorithm for the classification task?", "options": ["Decision trees", "Support vector machines", "Logistic regression", "K‑nearest neighbors"], "correct_index": 2, "explanation": "The hints explicitly mention using logistic regression for the classification task.", "citations": ["(No specific source; derived from STYLE HINTS)"]}
{"type": "objectives", "question": "The course outline includes topics such as linear regression, logistic regression, epoch, learning rate, and batch size.", "options": ["True", "False"], "correct_index": 0, "explanation": "The transcript states that the previous class covered fundamentals like linear regression, epoch, learning rate, and batch size, confirming their inclusion in the outline.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "objectives", "question": "In the class, precision is defined as true positive divided by the sum of true positive and false positive.", "options": ["True", "False"], "correct_index": 0, "explanation": "The discussion on evaluation metrics explicitly describes precision as TP / (TP + FP).", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"]}
{"type": "mcq", "question": "Which of the following best describes the purpose of a 80/20 train‑test split mentioned in the course?", "options": ["To allocate 80 % of data for testing and 20 % for training", "To allocate 80 % of data for training and 20 % for testing", "To ensure both training and testing sets contain exactly the same number of samples", "To perform cross‑validation with 80 folds"], "correct_index": 1, "explanation": "The style hint and class notes say “you split your data sets into 8020,” meaning 80 % training, 20 % testing.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In logistic regression for binary classification, which activation function is typically applied to the linear output to obtain probabilities?", "options": ["ReLU", "Sigmoid", "Tanh", "Softmax"], "correct_index": 1, "explanation": "Logistic regression uses the sigmoid function to map the linear combination to a probability between 0 and 1.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3  - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which metric would you examine if you want to know how many of the actual positive cases were correctly identified by the model?", "options": ["Accuracy", "Precision", "Recall", "F1‑score"], "correct_index": 2, "explanation": "Recall (also called the true positive rate) measures TP / (TP + FN), i.e., how many actual positives were captured.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"]}
{"type": "mcq", "question": "When working with Python dictionaries, which syntax correctly retrieves the value associated with the key `'year'` in the dictionary `car`?", "options": ["`car.year`", "`car['year']`", "`car(year)`", "`car->year`"], "correct_index": 1, "explanation": "Dictionary values are accessed with square brackets and the key string, e.g., `car['year']`.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 3 CLASS 2  - Recording Transcript.txt"]}
{"type": "mcq", "question": "The class mentioned using Matlab for “no‑code” work because it is:", "options": ["Free for all students", "Not free but provided through a free subscription service", "Only available on Windows machines", "Open‑source and editable"], "correct_index": 1, "explanation": "The transcript notes “Matlab is not free, but for everything will be using this class. You will be around the free subscription of the SCREE.”", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following statements about cross‑validation is true according to the instructor’s guidance?", "options": ["Five‑four cross validation means 5 folds for training and 4 folds for testing simultaneously", "Five‑fold cross validation splits data into five equal parts, iterating each part as the test set once", "Four‑fold cross validation is preferred over five‑fold for logistic regression", "Cross‑validation is not needed if you have an 80/20 split"], "correct_index": 1, "explanation": "The instructor referenced “five‑four cross validation,” which is a mis‑statement; the standard approach is five‑fold cross validation where each of the five parts serves as test set once.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following best describes the relationship between batch size and learning updates in gradient descent?", "options": ["Larger batch size results in more frequent weight updates", "Smaller batch size results in more frequent weight updates", "Batch size does not affect the frequency of updates", "Batch size only matters for inference, not training"], "correct_index": 1, "explanation": "A smaller batch processes fewer samples per update, leading to more frequent weight updates.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "fill_blank", "question": "Accuracy is calculated as (_____ + _____ ) / total samples.", "options": [], "correct_index": 0, "explanation": "Accuracy aggregates correctly classified positives and negatives over all samples.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1  - Recording Transcript (1).txt"], "answer": "true positive, true negative"}
{"type": "fill_blank", "question": "In the context of binary classification, the term “epoch” refers to a full pass over the _____ .", "options": [], "correct_index": 0, "explanation": "An epoch is one complete iteration through the entire training data.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"], "answer": "training dataset"}
{"type": "fill_blank", "question": "The logistic regression decision boundary is obtained by applying a _____ function to the linear combination of inputs.", "options": [], "correct_index": 0, "explanation": "Logistic regression uses the sigmoid activation to convert linear scores to probabilities.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 3  - Recording Transcript.txt"], "answer": "sigmoid"}
{"type": "coding", "question": "Implement a function `predict_logistic(weights, bias, X)` that returns a NumPy array of binary predictions (0 or 1) for a 2‑D input matrix `X` using the sigmoid activation and a threshold of 0.5.", "options": [], "correct_index": 0, "explanation": "The task reinforces understanding of logistic regression inference: linear combination → sigmoid → binary threshold.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "prompt": "", "starter_code": "", "tests": ["Verify that with weights `[1, -1]`, bias `0`, and X `[[2,1],[0,3]]` the function returns `[1,0]`.", "Check that probabilities are correctly computed for a simple case where logits are zero (output should be 0.5 → prediction 1)."]}
{"type": "mcq", "question": "Which of the following hyper‑parameters controls how big a step the optimizer takes during gradient descent?", "options": ["Batch size", "Learning rate", "Number of epochs", "Regularization strength"], "correct_index": 1, "explanation": "The learning rate determines the step size for each update in gradient descent.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In binary classification, which metric is defined as TP / (TP + FP)?", "options": ["Recall", "Accuracy", "Precision", "F1‑score"], "correct_index": 2, "explanation": "Precision is calculated as true positives divided by the sum of true positives and false positives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which Python data structure uses key‑value pairs and allows access via keys?", "options": ["List", "Tuple", "Dictionary", "Set"], "correct_index": 2, "explanation": "Dictionaries store data as key‑value pairs and you retrieve values by their keys.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1 - Recording Transcript (1).txt"]}
{"type": "mcq", "question": "What does the term “batch size” refer to in training a model?", "options": ["Total number of training samples", "Number of samples processed before the model’s internal parameters are updated", "Number of epochs to run", "Learning rate multiplier"], "correct_index": 1, "explanation": "Batch size is the number of training examples used in one forward/backward pass before updating weights.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which of the following best describes logistic regression?", "options": ["A method for predicting continuous values", "A classification algorithm that outputs probabilities for binary outcomes", "A clustering technique", "A dimensionality reduction method"], "correct_index": 1, "explanation": "Logistic regression is used for binary classification and provides probability estimates.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "In the context of model evaluation, a high recall value indicates:", "options": ["Few false positives", "Few false negatives", "High overall accuracy", "Balanced precision and recall"], "correct_index": 1, "explanation": "Recall measures the proportion of actual positives correctly identified, so a high recall means few false negatives.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type": "mcq", "question": "Which statement about the “free subscription of the SCREE” mentioned in the class is correct?", "options": ["It provides a paid MATLAB license", "It offers a free service for running MATLAB code", "It replaces the need for any programming language", "It is only available for advanced AI courses"], "correct_index": 1, "explanation": "The transcript notes that the free subscription of the SCREE service allows students to use MATLAB for the class.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 4 CLASS 1 - Recording Transcript (1).txt"]}
{"type": "fill_blank", "question": "The metric that measures the proportion of true positives among all predicted positives is called _______.", "options": [], "correct_index": 0, "explanation": "Precision is defined as TP / (TP + FP).", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "precision"}
{"type": "fill_blank", "question": "In logistic regression, the output is transformed by the _______ function to map values between 0 and 1.", "options": [], "correct_index": 0, "explanation": "Logistic regression uses the sigmoid (logistic) function to convert linear outputs into probabilities.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "answer": "sigmoid"}
{"type": "fill_blank", "question": "A _______ epoch means the model has seen the entire training dataset once.", "options": [], "correct_index": 0, "explanation": "One epoch corresponds to one full pass through the training data.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"], "answer": "single"}
{"type": "coding", "question": "Write a Python function `predict_logistic(weights, bias, X)` that returns the probability predictions for a binary logistic regression model using the sigmoid activation.", "options": [], "correct_index": 0, "explanation": "The function follows the standard logistic regression prediction formula: sigmoid(w·x + b).", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"], "prompt": "|\n  import numpy as np\n\n  def predict_logistic(weights, bias, X):\n      \"\"\"", "starter_code": "|\n  import numpy as np\n\n  def predict_logistic(weights, bias, X):\n      # compute linear combination\n      z = np.dot(X, weights) + bias\n      # apply sigmoid\n      prob = 1 / (1 + np.exp(-z))\n      return prob", "tests": ["Verify that for weights=[0,0], bias=0, X=[[0,0],[1,1]] the output is [0.5, 0.5].", "Verify that increasing a positive weight increases probability for larger feature values."]}
{"type": "general", "question": "What does the abbreviation “AI” stand for?", "options": ["Automated Interface", "Artificial Intelligence", "Adaptive Integration", "Analytic Input"], "correct_index": 1, "explanation": "AI is commonly used to denote Artificial Intelligence.", "citations": []}
{"type": "general", "question": "Which of the following is a typical use case for machine learning?", "options": ["Sorting a list of numbers", "Predicting house prices from historical data", "Compiling source code", "Rendering 3D graphics"], "correct_index": 1, "explanation": "Predicting house prices is a classic supervised learning problem.", "citations": []}
{"type": "objectives", "question": "The previous class covered fundamental concepts including linear regression, epoch, learning rate, and batch size.", "options": ["True", "False"], "correct_index": 0, "explanation": "The transcript confirms that these topics were discussed in the last class.", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 2 CLASS 1 - Recording Transcript.txt"]}
{"type": "objectives", "question": "Precision in binary classification is defined as true positives divided by the sum of true positives and false positives.", "options": ["True", "False"], "correct_index": 0, "explanation": "The transcript clearly defines precision as TP / (TP + FP).", "citations": ["data\\ARTIFICIAL INTELLIGENCE WEEK 5 CLASS 2 - Recording Transcript.txt"]}
{"type":"mcq","question":"Given the array of fruits below, select the appropriate method to replace 'apple' with 'lemon'.\nfruits = ['apple', 'banana', 'cherry']","options":["fruits[0] = 'lemon'","fruits[2] = 'lemon'","Error: lists are immutable","fruits.replace('apple','lemon')"],"correct_index":0,"explanation":"Lists are mutable; assign by index to overwrite the first element."}
{"type":"mcq","question":"In computer programming, what is debugging?","options":["Finding and fixing bugs","Finding and fixing errors in a program","Writing new features into a program","Documenting code for other programmers"],"correct_index":1,"explanation":"Debugging is the process of locating and correcting errors/defects in code."}
{"type":"mcq","question":"Data annotation is the process of assigning true value to data. Given a folder of images named like 0001_cat.jpg, 0003_dog.jpg, etc., which option is an inappropriate way to annotate for a classification task?","options":["By Name: Keep one folder and distinguish by file name","By Folder: Separate images into two folders (cat and dog)","By Binning: Group into ranges/histograms based on observed patterns","By Mapping: Create a CSV mapping each filename to its class label"],"correct_index":2,"explanation":"Binning by histogram patterns isn’t an annotation method; it changes data distribution rather than labeling."}
{"type":"mcq","question":"Outliers are values distant from most others in a feature. Which option is NOT a reasonable way to handle outliers?","options":["Simply delete the outliers with justification","Clip extreme values to bounds","Use transformations or robust scaling","Ignore them entirely without analysis"],"correct_index":3,"explanation":"Unexamined ignoring can harm model quality; others are standard treatments when justified."}
{"type":"mcq","question":"Which of the following features is categorical data?","options":["Temperature","Height","Age","Dialing code"],"correct_index":3,"explanation":"Dialing/country code is an identifier; treat it as categorical, not continuous."}
{"type":"mcq","question":"Which of the following features is numerical data?","options":["Discretized Temperature","Binned Temperature","Height","Postal Code"],"correct_index":2,"explanation":"Height is a continuous numeric variable; the others are categorical/identifiers."}
{"type":"objectives","question":"Binning is a technique for transforming categorical data into numerical data.","options":["Yes","No"],"correct_index":1,"explanation":"Binning typically converts numeric variables into categories, not the other way around."}
{"type":"objectives","question":"A machine learning model can train directly on raw string values (e.g., 'Cammeo', 'Osmancik') without any numeric encoding.","options":["Yes","No"],"correct_index":1,"explanation":"Models require numeric representations (e.g., one-hot, embeddings) of string categories."}
{"type":"mcq","question":"You are training on a dataset with the categorical feature eye_color ∈ {amber, blue, brown, gray, green, hazel}. Which of the following is a valid one-hot encoding for the value blue?","options":["[1, 2, 3, 4, 5, 6]","[0, 1]","[1, 0, 2, 3, 4, 5]","[0, 1, 0, 0, 0, 0]"],"correct_index":3,"explanation":"One-hot encoding uses a vector with a single 1 at the class index and 0 elsewhere (length equals number of classes)."}
{"type":"mcq","question":"In which scenario does it make sense to apply feature embeddings?","options":["The number of categorical feature values is very small","The model is trained offline","All possible categorical values can be enumerated easily","The number of categorical feature values is very large"],"correct_index":3,"explanation":"Embeddings shine with high-cardinality categorical features (e.g., users, items, words)."}
{"type":"mcq","question":"You perform a feature cross between two categorical features: apple_color ∈ {green, red, white, yellow} and apple_texture ∈ {crisp, mushy}. How many entries are in the resulting cross vector?","options":["8","6","4","2"],"correct_index":0,"explanation":"Cardinality multiplies: 4 × 2 = 8."}
{"type":"mcq","question":"You want to normalize the feature birth_weight (continuous). Which normalization is generally most appropriate?","options":["Clipping","Log scaling","Z-score scaling","Linear scaling (min-max)"],"correct_index":2,"explanation":"Z-score standardization is a common default for approximately normal continuous features."}
{"type":"mcq","question":"Which of the following is NOT a form of feature engineering or transformation?","options":["Binning","One-hot encoding","Normalization","Hyperparameter tuning"],"correct_index":3,"explanation":"Hyperparameter tuning configures the model; it is not a feature transformation."}
{"type":"mcq","question":"Your training data for a shoe recommendation model contains shoe_size values that should be between 6 and 16. For six examples you have: 8.5, 9, N/A, 105, 11, 9. Which examples should be deleted prior to training?","options":["Examples 1 & 2","Examples 3 & 4","Examples 4 & 5","Examples 5 & 6"],"correct_index":1,"explanation":"Example 3 is missing (N/A), and 105 is an extreme outlier/out-of-range; both should be removed or corrected."}
{"type":"mcq","question":"Which of the following is NOT a common method for handling missing data?","options":["Imputation","Deletion","Binning","Using a special 'missing' category"],"correct_index":2,"explanation":"Binning is not a method for handling missing data; it is a feature transformation technique."}
{"type":"fill_blank","question":"The process of converting categorical variables into a form that can be provided to machine learning algorithms is called _______.","options":[],"correct_index":0,"explanation":"This process is known as encoding, such as one-hot encoding or label encoding.","citations":[],"answer":"encoding"}
{"type":"fill_blank","question":"A feature that takes on a limited number of distinct values, often representing categories or groups, is called a _______ feature.","options":[],"correct_index":0,"explanation":"Such features are referred to as categorical features.","citations":[],"answer":"categorical"}
{"type":"fill_blank","question":"When normalizing a continuous feature to have zero mean and unit variance, the technique used is called _______ scaling.","options":[],"correct_index":0,"explanation":"This technique is known as Z-score scaling or standardization.","citations":[],"answer":"Z-score"}
{"type":"coding","question":"Write a Python function `one_hot_encode(categories, value)` that takes a list of unique categories and a specific value, returning a one-hot encoded list representing the value.","options":[],"correct_index":0,"explanation":"The function should create a binary vector where the index corresponding to the value is set to 1 and all other indices are set to 0.","citations":[],"prompt":"","starter_code":"","tests":["Verify that one_hot_encode(['red', 'green', 'blue'], 'green') returns [0, 1, 0].","Verify that one_hot_encode(['cat', 'dog', 'fish'], 'cat') returns [1, 0, 0]."]}
{"type":"mcq","question":"Which of the following is NOT a type of Machine Learning (ML) Systems?","options":["Reinforcement Learning","Imitation Learning","Supervised Learning","Unsupervised Learning"],"correct_index":1,"explanation":"The three primary ML paradigms are supervised, unsupervised, and reinforcement learning. Imitation learning is usually treated as a sub-area (often under RL), not a primary category."}
{"type":"mcq","question":"Select the odd example of Binary Classification.","options":["Predict Rainy or not Rainy","Predict Spam Messages","Predict Binary States","Predict Energy Usage"],"correct_index":3,"explanation":"Predicting energy usage is a regression problem (continuous value), while the others are binary classification tasks."}
{"type":"mcq","question":"What distinguishes a supervised approach from an unsupervised approach?","options":["A supervised approach typically uses clustering.","An unsupervised approach knows how to label clusters of data.","A supervised approach is given data that contains the correct answer.","A supervised approach interacts with the environment to get reward."],"correct_index":2,"explanation":"Supervised learning uses labeled data (features paired with target labels). Clustering is unsupervised; environment/reward is reinforcement learning."}
{"type":"mcq","question":"Why does a model need to be trained before it can make predictions?","options":["So it won’t require data to make a prediction.","A model doesn’t need to be trained; models are available on most computers.","To test the GPU functionality of a computer.","Just as humans need training, a model needs training to learn patterns from data."],"correct_index":3,"explanation":"Training estimates parameters from data so the model learns patterns it can generalize from; the other options are incorrect."}
{"type":"mcq","question":"For a reinforcement learning task, select the odd constituent.","options":["Action","Environment","Agent","State","Reward","Robotics"],"correct_index":5,"explanation":"Core RL elements are agent, environment, state, action, and reward. Robotics is an application domain, not a required RL constituent."}
{"type":"mcq","question":"Given the array of fruits below, select the appropriate method to replace 'apple' with 'lemon'.\nfruits = ['apple', 'banana', 'cherry']","options":["fruits[0] = 'lemon'","fruits[2] = 'lemon'","Error: lists are immutable","fruits.replace('apple','lemon')"],"correct_index":0,"explanation":"Python lists are mutable; assign by index to overwrite the first element. There is no list.replace method."}
{"type":"mcq","question":"Given the array of fruits below, select the appropriate method to replace the 'apple' with 'lemon'.\nfruits = ('apple', 'banana', 'cherry')","options":["fruits[0] = 'lemon'","fruits[2] = 'lemon'","Error: tuple is immutable","fruits[2] = 'lamon'"],"correct_index":2,"explanation":"Tuples are immutable in Python; you cannot assign to an index."}
{"type":"mcq","question":"Select the option to retrieve the car’s image from the car dictionary variable.\ncar = {\n  'name': 'Toyota',\n  'model': 'Camry',\n  'year': 2025,\n  'image': 'https://.../toyota-camry.png'\n}","options":["car[1]","car['image1']","car[3]","car['image']"],"correct_index":3,"explanation":"Access the value by its key string: car['image']."}
{"type":"mcq","question":"In computer programming, what is debugging?","options":["Finding and fixing beetbugs","Finding and fixing errors in a program","Writing new features into a program","Documenting code for other programmers"],"correct_index":1,"explanation":"Debugging is the process of locating and correcting errors/defects in code."}
{"type":"mcq","question":"Which of the following best describes Artificial Intelligence?","options":["A system that strictly follows human-written rules","A field focused on enabling machines to perform tasks that typically require human intelligence","A set of physical robots that look like humans","Any program that displays text output"],"correct_index":1,"explanation":"AI focuses on creating systems capable of intelligent behavior, not limited to rule-based programs or physical robots."}
{"type":"mcq","question":"Which of the following correctly distinguishes AI, Machine Learning, and Deep Learning?","options":["AI ⊂ ML ⊂ DL","ML ⊂ DL ⊂ AI","DL ⊂ ML ⊂ AI","They all refer to the same thing"],"correct_index":2,"explanation":"Deep Learning is a subset of Machine Learning, which is a subset of Artificial Intelligence."}
{"type":"true_false","question":"Deep Learning models are always better than traditional Machine Learning models.","options":["True","False"],"correct_index":1,"explanation":"Deep Learning requires large data and compute; traditional models often outperform DL on small structured datasets."}
{"type":"mcq","question":"Which scenario is BEST suited for a rule-based program rather than Machine Learning?","options":["Detecting spam emails","Calculating if a number is even or odd","Predicting house prices","Recommending products to users"],"correct_index":1,"explanation":"Even/odd detection is deterministic and does not require pattern learning."}
{"type":"mcq","question":"Which part of the AI workflow does data collection belong to?","options":["Model Training","Model Deployment","Preprocessing and Data Preparation","Prediction Stage"],"correct_index":2,"explanation":"Data collection and preprocessing are early steps before model training."}
{"type":"true_false","question":"Better data quality can improve model performance even without changing the algorithm.","options":["True","False"],"correct_index":0,"explanation":"Data quality often impacts results more than model complexity."}
{"type":"mcq","question":"Which real-world task is most suitable for Machine Learning?","options":["Adding two numbers","Translating text from English to French","Displaying static images on a website","Opening a file from disk"],"correct_index":1,"explanation":"Language translation involves complex pattern recognition suited for ML."}
{"type":"fill_blank","question":"The process of exposing a trained model for real-world use is called ________.","answer":"deployment","explanation":"Model deployment makes predictions accessible to users or applications."}
{"type":"mcq","question":"Which environment is commonly used in AI bootcamps for rapid experimentation?","options":["Microsoft Word","Google Colab","Notepad","Paint 3D"],"correct_index":1,"explanation":"Google Colab supports Python execution in the cloud with GPU access."}
{"type":"true_false","question":"In supervised learning, the model is trained using labeled data.","options":["True","False"],"correct_index":0,"explanation":"Supervised learning relies on input-output pairs."}
{"type":"mcq","question":"Which of the following is a classification problem?","options":["Predicting future temperature","Detecting if an email is spam or not","Estimating the age of a person in years","Clustering customers by behavior"],"correct_index":1,"explanation":"Spam detection is binary classification."}
{"type":"mcq","question":"What role does NumPy play in AI development?","options":["Data visualization","Array and numerical computation","Web scraping","Database storage"],"correct_index":1,"explanation":"NumPy provides efficient array computations used in ML pipelines."}
{"type":"true_false","question":"Pandas DataFrame is used mainly for handling tabular data.","options":["True","False"],"correct_index":0,"explanation":"Pandas provides labeled data structures like DataFrame for tables."}
{"type":"fill_blank","question":"A model that predicts continuous numeric values is solving a ________ problem.","answer":"regression","explanation":"Regression predicts continuous quantities, unlike classification."}
{"type":"mcq","question":"Why is Python preferred for AI development?","options":["It is the fastest compiled language","It has rich libraries like NumPy, Pandas, and scikit-learn","It cannot handle errors","It is only used in web development"],"correct_index":1,"explanation":"Python’s ecosystem makes it ideal for ML experimentation and production."}
{"type":"mcq","question":"Which of the following best defines supervised learning?","options":["Learning from unlabeled data","Learning by interacting with an environment through rewards","Learning from labeled input-output pairs","Random guessing followed by feedback"],"correct_index":2,"explanation":"Supervised learning requires labeled data that pairs inputs with correct outputs."}
{"type":"mcq","question":"Which type of problem is predicting house prices from square footage and number of rooms?","options":["Classification","Regression","Clustering","Reinforcement"],"correct_index":1,"explanation":"House price prediction is a regression task because it outputs continuous numeric values."}
{"type":"true_false","question":"Unsupervised learning requires labeled data to work effectively.","options":["True","False"],"correct_index":1,"explanation":"Unsupervised learning does not rely on labeled data; it discovers structure in unlabeled data."}
{"type":"mcq","question":"Which scenario best fits clustering?","options":["Detecting fraudulent transactions","Grouping customers with similar purchasing behavior","Predicting tomorrow\u2019s temperature","Classifying emails as spam or not spam"],"correct_index":1,"explanation":"Clustering groups similar data points without labels."}
{"type":"mcq","question":"In reinforcement learning, which of the following is NOT a core component?","options":["Agent","Reward","Environment","Label"],"correct_index":3,"explanation":"Labels are used in supervised learning, not reinforcement learning."}
{"type":"fill_blank","question":"In supervised learning, the input features are called ________, and the target output is called the ________.","answer":"features, label","explanation":"Features are the inputs to the model; the label is the output being predicted."}
{"type":"mcq","question":"Which of the following is an example of classification?","options":["Predicting CO2 emissions of a car in grams","Determining whether a patient has a disease or not","Estimating stock price for tomorrow","Grouping customers based on spending"],"correct_index":1,"explanation":"Disease/no disease is a binary classification task."}
{"type":"true_false","question":"A train-test split is used to evaluate how well a model generalizes to unseen data.","options":["True","False"],"correct_index":0,"explanation":"The training set is used to learn, while the test set evaluates generalization."}
{"type":"mcq","question":"Which function in scikit-learn is typically used for splitting data into train and test sets?","options":["train_split()","split_data()","train_test_split()","divide_data()"],"correct_index":2,"explanation":"The correct function is sklearn.model_selection.train_test_split()."}
{"type":"mcq","question":"Which metric measures the average of squared differences between predicted and actual values?","options":["Accuracy","F1-score","Mean Squared Error (MSE)","Recall"],"correct_index":2,"explanation":"MSE is the average squared difference between predictions and actual values in regression."}
{"type":"mcq","question":"Which metric indicates how well a regression model explains variance in the target variable?","options":["R-squared (R²)","Precision","Confusion Matrix","ROC-AUC"],"correct_index":0,"explanation":"R-squared measures the proportion of variance explained by the model."}
{"type":"true_false","question":"A higher R² value indicates better model performance in regression.","options":["True","False"],"correct_index":0,"explanation":"R² ranges from 0 to 1; higher values mean better fit."}
{"type":"mcq","question":"Which of the following describes overfitting?","options":["Model performs well on train and test data","Model performs poorly on both train and test data","Model performs well on training data but poorly on test data","Model performs poorly on training data but well on test data"],"correct_index":2,"explanation":"Overfitting occurs when the model memorizes training data and fails to generalize."}
{"type":"mcq","question":"Which model is commonly used for basic regression tasks in scikit-learn?","options":["LogisticRegression","LinearRegression","RandomForestClassifier","KMeans"],"correct_index":1,"explanation":"LinearRegression is used for regression tasks."}
{"type":"true_false","question":"Linear regression can be used for both regression and classification.","options":["True","False"],"correct_index":1,"explanation":"Linear regression outputs continuous values and is not suitable for classification."}
{"type":"fill_blank","question":"In supervised learning, the dataset is split into ________ set for learning and ________ set for evaluation.","answer":"training, testing","explanation":"A basic train-test split separates training and testing sets."}
{"type":"mcq","question":"Which of the following problems would MOST likely use unsupervised learning?","options":["Diagnosing a disease from X-ray images","Clustering news articles by topic","Predicting car price","Detecting spam emails"],"correct_index":1,"explanation":"Clustering news into topics without labeled categories is unsupervised."}
{"type":"coding_logic","question":"What will sklearn.model_selection.train_test_split(X, y, test_size=0.25) do?","options":["Assign 75% to training and 25% to testing","Assign 25% to training and 75% to testing","Assign 50% to training and 50% to testing","Shuffle data without splitting"],"correct_index":0,"explanation":"test_size=0.25 allocates 25% of data to test set."}
{"type":"true_false","question":"Regression problems can use MSE and R² for evaluation.","options":["True","False"],"correct_index":0,"explanation":"Both metrics are common for regression performance assessment."}
{"type":"mcq","question":"Which statement best differentiates regression and classification?","options":["Regression predicts categories, classification predicts numbers","Regression predicts continuous values, classification predicts labels","Both predict the same type of outputs","Regression is unsupervised while classification is supervised"],"correct_index":1,"explanation":"Regression outputs continuous quantities, while classification outputs categories."}
{"type":"mcq","question":"Which of the following represents the correct order of an ML pipeline?","options":["Train → Evaluate → Split → Collect","Split → Train → Evaluate","Evaluate → Train → Split","Collect → Evaluate → Train"],"correct_index":1,"explanation":"Split data first, train the model, then evaluate it."}
{"type":"true_false","question":"In supervised learning, labels are required during training but not during prediction.","options":["True","False"],"correct_index":0,"explanation":"Once trained, the model predicts without seeing the true labels."}
{"type":"mcq","question":"Which learning method is best for a recommendation system grouping similar users?","options":["Supervised","Unsupervised","Reinforcement","None"],"correct_index":1,"explanation":"Grouping similar users without labels is unsupervised clustering."}
{"type":"fill_blank","question":"Mean Squared Error (MSE) is calculated as the mean of ( ________ − ________ )².","answer":"predicted, actual","explanation":"MSE penalizes squared differences between predicted and actual values."}
{"type":"coding_logic","question":"If train_test_split is called without random_state, what happens?","options":["Data splits will be identical every time","Data splits will be random every execution","No split will occur","Only labels will be split"],"correct_index":1,"explanation":"Without random_state, the split changes with every run due to randomness."}
{"type":"mcq","question":"Which of the following is a binary classification problem?","options":["Predicting stock prices","Detecting spam vs. not spam in emails","Grouping customers by behavior without labels","Predicting age as a number"],"correct_index":1,"explanation":"Spam detection is a binary classification task with two labels."}
{"type":"mcq","question":"Which of the following is NOT a valid evaluation metric for classification?","options":["Accuracy","Precision","Mean Squared Error","F1-score"],"correct_index":2,"explanation":"MSE is used for regression, not classification."}
{"type":"true_false","question":"Precision measures how many of the predicted positives are actually positive.","options":["True","False"],"correct_index":0,"explanation":"Precision = TP / (TP + FP)."}
{"type":"true_false","question":"Recall is also known as sensitivity or true positive rate.","options":["True","False"],"correct_index":0,"explanation":"Recall = TP / (TP + FN)."}
{"type":"fill_blank","question":"In a confusion matrix, the count of actual negatives incorrectly predicted as positives is called ________.","answer":"false positives","explanation":"False positives (FP) are negative samples predicted as positive."}
{"type":"mcq","question":"Which scenario requires high recall over precision?","options":["Spam detection, to avoid annoying users with wrong blocks","Cancer diagnosis, to ensure no positive case is missed","Recommending products, to avoid irrelevant ads","Credit card approval, to minimize fraud"],"correct_index":1,"explanation":"In medical diagnosis, missing a positive case (FN) is more harmful, so recall is prioritized."}
{"type":"mcq","question":"Which of the following models is primarily used for binary classification?","options":["LinearRegression","KMeans","LogisticRegression","PCA"],"correct_index":2,"explanation":"LogisticRegression outputs probabilities for binary outcomes."}
{"type":"mcq","question":"In logistic regression, the activation function applied to the linear combination of inputs is:","options":["ReLU","Sigmoid","Softmax","Tanh"],"correct_index":1,"explanation":"Sigmoid squashes the output into range (0,1)."}
{"type":"mcq","question":"Which of the following best describes a decision boundary?","options":["The limit of dataset size","A line or surface that separates classes in feature space","A region where model accuracy drops","A layer inside a neural network"],"correct_index":1,"explanation":"Decision boundaries split feature space between predicted classes."}
{"type":"true_false","question":"A perfect classifier has precision = 1 and recall = 1.","options":["True","False"],"correct_index":0,"explanation":"Perfect prediction yields no FP and no FN, leading to precision=1 and recall=1."}
{"type":"mcq","question":"What happens when a model overfits?","options":["It performs well on unseen data","It memorizes the training data and performs poorly on new data","It performs poorly on both training and test data","It ignores training data completely"],"correct_index":1,"explanation":"Overfitting means great training accuracy but poor generalization."}
{"type":"mcq","question":"Which of the following helps prevent overfitting in decision trees?","options":["Increase tree depth","Use more training data","Pruning or limiting depth","Use MSE as loss"],"correct_index":2,"explanation":"Limiting depth or pruning avoids overly complex trees."}
{"type":"mcq","question":"Which of the following is a key advantage of Random Forest over a single Decision Tree?","options":["Lower training time","Always 100% accuracy","Reduces overfitting through ensembling","Requires no data preprocessing"],"correct_index":2,"explanation":"Random Forest averages multiple trees to improve generalization."}
{"type":"true_false","question":"Random Forests reduce overfitting by training multiple trees on random subsets of data.","options":["True","False"],"correct_index":0,"explanation":"Bootstrap aggregating (bagging) ensures diversity across trees."}
{"type":"fill_blank","question":"The F1-score is the harmonic mean of Precision and ________.","answer":"Recall","explanation":"F1-score = 2 × (Precision × Recall) / (Precision + Recall)."}
{"type":"coding_logic","question":"If a logistic regression model predicts probabilities [0.8, 0.3, 0.6] with threshold 0.5, what are the predicted classes?","options":["[0,0,0]","[1,1,1]","[1,0,1]","[0,1,0]"],"correct_index":2,"explanation":"Prob >= 0.5 → 1; else 0."}
{"type":"mcq","question":"Which class in sklearn is used to compute a confusion matrix?","options":["confusion_matrix from sklearn.metrics","ConfusionMatrix from sklearn.tree","MatrixConfusion from sklearn.base","metrics.confusion"],"correct_index":0,"explanation":"The correct function is sklearn.metrics.confusion_matrix()."}
{"type":"true_false","question":"A high precision and low recall indicates that the model is conservative in predicting positives.","options":["True","False"],"correct_index":0,"explanation":"High precision = few false positives; low recall = many false negatives."}
{"type":"mcq","question":"Which of the following is NOT true about logistic regression?","options":["It outputs probabilities","It can handle non-linear relationships by default","It uses sigmoid activation","It is used for binary classification"],"correct_index":1,"explanation":"Logistic regression is inherently linear unless features are engineered."}
{"type":"scenario","question":"You built a spam filter that flags 100 emails as spam. 90 are truly spam and 10 are legitimate emails incorrectly blocked. What is the precision?","answer":"0.9","explanation":"Precision = TP / (TP + FP) = 90 / (90 + 10) = 0.9."}
{"type":"mcq","question":"Which metric should be prioritized for fraud detection to avoid missing fraudulent transactions?","options":["Precision","Recall","MSE","R²"],"correct_index":1,"explanation":"Missing fraud (FN) is costly; recall should be maximized."}
{"type":"true_false","question":"A confusion matrix can be extended to multi-class classification.","options":["True","False"],"correct_index":0,"explanation":"Confusion matrices work for binary and multi-class tasks."}
{"type":"fill_blank","question":"When a model predicts all samples as positive, the recall becomes ________.","answer":"1","explanation":"Recall = TP / (TP + FN); if no FN, recall = 1."}
{"type":"coding_logic","question":"What will be the output of sklearn.metrics.accuracy_score([1,0,1,1],[1,1,1,1])?","options":["0.25","0.5","0.75","1.0"],"correct_index":2,"explanation":"3 correct predictions out of 4 → 3/4 = 0.75."}
{"type":"mcq","question":"Which statement BEST describes underfitting?","options":["Model is too simple to capture patterns","Model memorizes training data","Model achieves high precision","Model achieves high recall"],"correct_index":0,"explanation":"Underfitting means the model is too basic, performing poorly on both train and test."}
{"type":"mcq","question":"Which of the following models is most likely to overfit without constraints?","options":["Linear Regression","Decision Tree","KMeans","KNN with k=50"],"correct_index":1,"explanation":"Decision trees can grow excessively deep unless pruned."}
{"type":"true_false","question":"Random Forests always guarantee higher accuracy than single decision trees in all cases.","options":["True","False"],"correct_index":1,"explanation":"Random Forests improve generalization but not guaranteed best for every dataset."}
{"type":"mcq","question":"Which metric is most useful when class distribution is imbalanced?","options":["Accuracy","Precision","Recall","F1-score"],"correct_index":3,"explanation":"F1-score balances precision and recall when data is imbalanced."}
{"type":"scenario","question":"A model has precision 0.95 and recall 0.40. What does this imply?","answer":"The model rarely predicts positives incorrectly (high precision) but misses many actual positives (low recall).","explanation":"High precision, low recall = conservative model that avoids false positives but allows false negatives."}
{"type":"mcq","question":"Which of the following is a common strategy for handling missing numerical values?","options":["Delete entire dataset","Replace with mean or median","Convert all values to strings","Randomly guess"],"correct_index":1,"explanation":"Imputation using mean or median is standard for numerical missing values."}
{"type":"true_false","question":"Dropping rows with missing values is always the best approach.","options":["True","False"],"correct_index":1,"explanation":"Dropping can lead to information loss; imputation is often better."}
{"type":"mcq","question":"Which Pandas method fills missing values in a column?","options":["df.replace_missing()","df.fillna()","df.clean()","df.nullfix()"],"correct_index":1,"explanation":"df.fillna() replaces NaN values."}
{"type":"coding_logic","question":"What does df['age'].fillna(df['age'].mean()) do?","options":["Deletes missing values","Replaces missing 'age' values with column mean","Drops the 'age' column","Converts 'age' to strings"],"correct_index":1,"explanation":"It imputes missing values using the column mean."}
{"type":"mcq","question":"Which of the following BEST identifies an outlier?","options":["Values very close to the median","Values far away from most of the data","Values that are equal to zero","Values in a sorted list"],"correct_index":1,"explanation":"Outliers are values significantly deviating from the majority."}
{"type":"true_false","question":"One-hot encoding converts categorical variables into binary indicator columns.","options":["True","False"],"correct_index":0,"explanation":"Each category becomes a 0/1 column."}
{"type":"mcq","question":"What does pd.get_dummies(df['color']) return?","options":["Numeric scaling","Encoded binary columns for each unique color","Column removal","Feature selection"],"correct_index":1,"explanation":"get_dummies produces one-hot encoded columns."}
{"type":"fill_blank","question":"The process of transforming numeric features to a standard scale (mean=0, std=1) is called ________.","answer":"standardization","explanation":"Standardization rescales feature distribution."}
{"type":"mcq","question":"Which scaler is used to bound values between 0 and 1?","options":["StandardScaler","MinMaxScaler","RobustScaler","Normalizer"],"correct_index":1,"explanation":"MinMaxScaler rescales values to range [0,1]."}
{"type":"mcq","question":"Which technique helps reduce the negative effect of extreme outliers on scaling?","options":["StandardScaler","RobustScaler","MinMaxScaler","None"],"correct_index":1,"explanation":"RobustScaler uses median and IQR, ignoring extreme outliers."}
{"type":"true_false","question":"Feature engineering involves creating new features from existing ones to improve model performance.","options":["True","False"],"correct_index":0,"explanation":"Combining or transforming features is feature engineering."}
{"type":"fill_blank","question":"Creating a new feature by dividing income by number of dependents is an example of ________ feature.","answer":"derived","explanation":"This is derived or engineered from existing features."}
{"type":"mcq","question":"Which method helps identify collinearity between numerical features?","options":["Correlation matrix","Confusion matrix","ROC curve","Elbow method"],"correct_index":0,"explanation":"Correlation matrix reveals feature correlations."}
{"type":"coding_logic","question":"What does df.isnull().sum() return?","options":["Sum of numeric columns","Total rows","Count of missing values per column","Error"],"correct_index":2,"explanation":"It calculates missing value count column-wise."}
{"type":"mcq","question":"Which encoding is best for ordinal categorical data (e.g., low < medium < high)?","options":["One-hot encoding","Label encoding","Random shuffling","Hashing"],"correct_index":1,"explanation":"Label encoding preserves order for ordinal features."}
{"type":"true_false","question":"One-hot encoding is preferred over label encoding for nominal categories.","options":["True","False"],"correct_index":0,"explanation":"Nominal categories have no order; one-hot is safer."}
{"type":"mcq","question":"What happens if you apply one-hot encoding to a column with 1000 unique values?","options":["Only one column created","Model becomes more interpretable","Many sparse columns are created","Data shrinks"],"correct_index":2,"explanation":"High-cardinality leads to sparse wide matrices."}
{"type":"scenario","question":"A dataset has a column 'salary' with extreme values like 1,000,000 compared to others near 50,000. What is the best first step?","answer":"Detect and treat outliers (e.g., using IQR or clipping) before scaling.","explanation":"Extreme values distort scaling and regression if not handled."}
{"type":"mcq","question":"Which of these is NOT a feature scaling technique?","options":["Standardization","Normalization","One-hot encoding","Robust scaling"],"correct_index":2,"explanation":"Encoding is not scaling."}
{"type":"fill_blank","question":"The Pandas method ________ can be used to remove duplicate rows.","answer":"drop_duplicates","explanation":"df.drop_duplicates() deletes repeated rows."}
{"type":"mcq","question":"What is the purpose of feature selection?","options":["Increase dataset size","Remove irrelevant features","Create new target labels","Duplicate data"],"correct_index":1,"explanation":"Feature selection keeps most informative features only."}
{"type":"true_false","question":"Scaling should be applied after train-test split to avoid data leakage.","options":["True","False"],"correct_index":0,"explanation":"Fit scaler on training set only, then transform test set."}
{"type":"mcq","question":"Which of the following methods fills missing numerical values based on relationships with other features?","options":["Mean imputation","KNN imputation","Dropping rows","Label encoding"],"correct_index":1,"explanation":"KNN imputation uses nearest neighbors for more accurate estimates."}
{"type":"fill_blank","question":"Using median instead of mean for imputation helps reduce sensitivity to ________.","answer":"outliers","explanation":"Median is robust against extreme values."}
{"type":"mcq","question":"Which Pandas code removes rows with any missing value?","options":["df.drop_missing()","df.rmna()","df.dropna()","df.delnull()"],"correct_index":2,"explanation":"df.dropna() removes rows with NaNs."}
{"type":"coding_logic","question":"What is the output of df['income'] / df['family_size']?","options":["Creates a new feature per row","Deletes rows","Renames columns","Sorts data"],"correct_index":0,"explanation":"It creates a derived ratio feature."}
{"type":"mcq","question":"Which of the following is a downside of one-hot encoding?","options":["Loss of interpretability","Increased dimensionality for high-cardinality features","Cannot be used with neural networks","Destroys numeric data"],"correct_index":1,"explanation":"One-hot expands columns significantly."}
{"type":"true_false","question":"You should perform feature scaling before applying KNN or K-Means.","options":["True","False"],"correct_index":0,"explanation":"Distance-based models require scaled features."}
{"type":"mcq","question":"Which feature engineering technique converts timestamps into day, month, year columns?","options":["Time decomposition","Spatial hashing","Data smoothing","Random projection"],"correct_index":0,"explanation":"Breaking timestamps improves temporal learning."}
{"type":"scenario","question":"A dataset has a 'country' column with 200 unique values. What encoding is best?","answer":"Use frequency encoding or hashing instead of one-hot to reduce dimensionality.","explanation":"High-cardinality features need compact encoding."}
{"type":"mcq","question":"Which of the following is an UNSUPERVISED learning algorithm?","options":["Linear Regression","K-Means Clustering","Logistic Regression","Naive Bayes"],"correct_index":1,"explanation":"K-Means groups data without labels, making it unsupervised."}
{"type":"true_false","question":"Unsupervised learning requires labeled data for training.","options":["True","False"],"correct_index":1,"explanation":"Unsupervised learning works without labeled outputs."}
{"type":"mcq","question":"What is the main objective of clustering?","options":["Predict future values","Group similar data points together","Reduce dataset size","Estimate feature importance"],"correct_index":1,"explanation":"Clustering discovers natural groupings in data based on similarity."}
{"type":"mcq","question":"Which distance metric is commonly used in K-Means clustering?","options":["Cosine similarity","Manhattan distance","Euclidean distance","Hamming distance"],"correct_index":2,"explanation":"Euclidean distance is the most widely used in K-Means."}
{"type":"fill_blank","question":"In K-Means, the number of groups to form is controlled by the parameter ________.","answer":"k","explanation":"The value of k determines how many clusters will be formed."}
{"type":"mcq","question":"Which of the following is an advantage of K-Means?","options":["Works well with categorical data by default","Scales efficiently to large datasets","Automatically determines number of clusters","Handles non-spherical clusters well"],"correct_index":1,"explanation":"K-Means is computationally efficient but assumes numeric inputs and spherical clusters."}
{"type":"mcq","question":"Which clustering algorithm can detect clusters of arbitrary shapes?","options":["K-Means","DBSCAN","Linear Regression","Logistic Regression"],"correct_index":1,"explanation":"DBSCAN groups based on density, allowing irregular shapes."}
{"type":"true_false","question":"DBSCAN requires specifying the number of clusters in advance.","options":["True","False"],"correct_index":1,"explanation":"DBSCAN does not require k; clusters emerge from density."}
{"type":"mcq","question":"Which parameter in DBSCAN defines the minimum number of points to form a dense region?","options":["eps","min_samples","max_iter","n_clusters"],"correct_index":1,"explanation":"min_samples controls how many neighbors are needed to form a dense region."}
{"type":"mcq","question":"What is a drawback of K-Means clustering?","options":["It handles non-linear relationships well","It struggles with different-sized clusters","It does not require numeric data","It never converges"],"correct_index":1,"explanation":"K-Means assumes spherical, equally-sized clusters."}
{"type":"coding_logic","question":"What does PCA(n_components=2) do in sklearn.decomposition.PCA?","options":["Selects two rows","Selects two columns only","Reduces dataset to 2 dimensions","Duplicates dataset twice"],"correct_index":2,"explanation":"It projects high-dimensional data into 2D space."}
{"type":"mcq","question":"What is the main goal of PCA?","options":["Remove missing values","Reduce dimensionality while preserving variance","Increase number of features","Cluster data using distance"],"correct_index":1,"explanation":"PCA captures maximum variance in fewer dimensions."}
{"type":"true_false","question":"PCA can help improve clustering performance by reducing noise.","options":["True","False"],"correct_index":0,"explanation":"PCA removes redundant information, making clusters clearer."}
{"type":"fill_blank","question":"The technique used to determine the best value for k in K-Means by plotting inertia vs k is called the ________ method.","answer":"elbow","explanation":"The elbow method finds the point where reducing inertia slows down."}
{"type":"mcq","question":"Which metric measures how well-separated clusters are?","options":["Silhouette Score","MSE","Accuracy","Precision"],"correct_index":0,"explanation":"Silhouette Score evaluates cohesion vs separation of clusters."}
{"type":"scenario","question":"A retail company wants to group customers based on spending habits without prior labels. Which learning method should they use?","answer":"Unsupervised learning with clustering (e.g., K-Means).","explanation":"Customer segmentation is a common clustering use case."}
{"type":"mcq","question":"Which of the following can be used for anomaly detection?","options":["K-Means","DBSCAN","Both","Neither"],"correct_index":2,"explanation":"Both K-Means (via large distances) and DBSCAN (via noise points) can detect anomalies."}
{"type":"true_false","question":"In K-Means, centroids are updated after each iteration based on assigned data points.","options":["True","False"],"correct_index":0,"explanation":"Centroids shift to mean positions of cluster members."}
{"type":"mcq","question":"What does the parameter n_clusters control in KMeans() from sklearn?","options":["Batch size","Number of iterations","Number of clusters","Number of features"],"correct_index":2,"explanation":"n_clusters specifies how many centroids to place."}
{"type":"fill_blank","question":"Applying PCA before clustering helps reduce ________ and improve performance.","answer":"dimensionality","explanation":"Lower dimensions make distance-based clustering more effective."}
{"type":"mcq","question":"Which clustering method assigns each point to the nearest centroid?","options":["Agglomerative clustering","DBSCAN","K-Means","Isolation Forest"],"correct_index":2,"explanation":"K-Means assigns points to the closest centroid based on distance."}
{"type":"true_false","question":"Hierarchical clustering builds clusters by successively merging or splitting groups.","options":["True","False"],"correct_index":0,"explanation":"Agglomerative (merge) or divisive (split) strategies are used in hierarchical clustering."}
{"type":"mcq","question":"Which of the following is NOT suitable for clustering numerical data?","options":["StandardScaler","OneHotEncoder","KMeans","DBSCAN"],"correct_index":1,"explanation":"Encoding is for categorical data, not clustering itself."}
{"type":"scenario","question":"You apply K-Means with k=3 but one cluster has only 1 data point. What likely happened?","answer":"The value of k is too high or the data is unevenly distributed.","explanation":"Poor cluster assignment indicates bad k choice or imbalanced data."}
{"type":"mcq","question":"Which of the following statements about clustering is NOT true?","options":["Clustering can discover hidden patterns in unlabeled data","Clustering can be used for exploratory data analysis","Clustering always produces perfect groupings","Clustering results depend on chosen distance metric"],"correct_index":2,"explanation":"Clustering is heuristic and rarely perfect — results depend on many choices."}
{"type":"mcq","question":"What distinguishes Deep Learning from traditional Machine Learning?","options":["Deep Learning manually selects features","Deep Learning uses multi-layer neural networks","Deep Learning cannot learn from images","Machine Learning is always more accurate"],"correct_index":1,"explanation":"Deep Learning uses multiple layers to automatically learn representations."}
{"type":"true_false","question":"A perceptron is the simplest form of a neural network.","options":["True","False"],"correct_index":0,"explanation":"A perceptron is a single neuron with input weights and activation."}
{"type":"mcq","question":"Which activation function outputs values between 0 and 1?","options":["ReLU","Sigmoid","Tanh","Linear"],"correct_index":1,"explanation":"Sigmoid squashes inputs into [0,1]."}
{"type":"mcq","question":"What is the main drawback of sigmoid activation?","options":["It is not differentiable","It saturates and causes vanishing gradients","It outputs negative values only","It requires image input"],"correct_index":1,"explanation":"Sigmoid gradients become very small for large inputs."}
{"type":"coding_logic","question":"What is the output of np.maximum(0, -5) when used as ReLU?","options":["-5","0","5","Error"],"correct_index":1,"explanation":"ReLU(x) = max(0, x). Negative inputs become 0."}
{"type":"true_false","question":"ReLU can output negative values.","options":["True","False"],"correct_index":1,"explanation":"ReLU clips negatives to zero."}
{"type":"mcq","question":"Which Keras layer is most commonly used for fully connected layers?","options":["Conv2D","Dense","MaxPooling2D","Dropout"],"correct_index":1,"explanation":"Dense creates fully connected layers."}
{"type":"mcq","question":"What does this Keras code create?\nmodel = Sequential([Dense(64, activation='relu'), Dense(1, activation='sigmoid')])","options":["A regression model","A binary classification model","A clustering model","An unsupervised autoencoder"],"correct_index":1,"explanation":"Sigmoid output implies binary classification."}
{"type":"fill_blank","question":"The layer that receives the raw input data is called the ________ layer.","answer":"input","explanation":"The input layer is the first layer of a neural network."}
{"type":"fill_blank","question":"The layer that makes the final prediction is called the ________ layer.","answer":"output","explanation":"The output layer returns classification or regression values."}
{"type":"mcq","question":"What is the main purpose of dropout in neural networks?","options":["Speed up training","Prevent overfitting by randomly deactivating neurons","Convert labels to one-hot format","Increase number of layers"],"correct_index":1,"explanation":"Dropout randomly zeros neurons to reduce reliance on specific pathways."}
{"type":"true_false","question":"Deep Learning models typically require more data than traditional ML models.","options":["True","False"],"correct_index":0,"explanation":"Neural networks learn many parameters and need lots of data."}
{"type":"mcq","question":"Which of the following best describes backpropagation?","options":["Process of initializing weights","Method of computing gradients to update weights","Technique for feature scaling","Hyperparameter tuning"],"correct_index":1,"explanation":"Backpropagation is used to adjust weights via gradient descent."}
{"type":"mcq","question":"Which activation function is commonly used in hidden layers of neural networks?","options":["Sigmoid","ReLU","Softmax","Step function"],"correct_index":1,"explanation":"ReLU is efficient and avoids vanishing gradients."}
{"type":"true_false","question":"Softmax activation is suitable for multi-class classification.","options":["True","False"],"correct_index":0,"explanation":"Softmax outputs probability distribution over multiple classes."}
{"type":"mcq","question":"Which loss function is commonly used for binary classification in neural networks?","options":["Mean Squared Error","Binary Crossentropy","Categorical Crossentropy","Hinge Loss"],"correct_index":1,"explanation":"Binary crossentropy works with sigmoid activation."}
{"type":"mcq","question":"Which of the following indicates overfitting in deep learning?","options":["High training accuracy, low test accuracy","High test accuracy, low training accuracy","Both accuracies are equal","Model never converges"],"correct_index":0,"explanation":"Overfitting means memorizing training data without generalization."}
{"type":"fill_blank","question":"The process of reducing learning rate when validation accuracy stops improving is called ________ scheduling.","answer":"learning rate","explanation":"Learning rate scheduling improves convergence."}
{"type":"mcq","question":"Which of the following is true about batch size in training?","options":["Larger batches always lead to better models","Smaller batches make updates more frequent","Batch size must be equal to dataset size","Batch size has no effect"],"correct_index":1,"explanation":"Smaller batches lead to more updates per epoch."}
{"type":"coding_logic","question":"If a Dense layer has 3 input features and 4 output neurons, how many weights are learned (excluding bias)?","options":["7","12","4","3"],"correct_index":1,"explanation":"Weights = input × output = 3 × 4 = 12."}
{"type":"true_false","question":"Activation functions introduce non-linearity into neural networks.","options":["True","False"],"correct_index":0,"explanation":"Without non-linearity, networks behave like linear models."}
{"type":"mcq","question":"Which Keras argument specifies the optimization algorithm?","options":["model.compile(optimizer='adam')","model.build(optimizer='adam')","model.fit(optimizer='adam')","model.run(optimizer='adam')"],"correct_index":0,"explanation":"The optimizer is set during compile()."}
{"type":"mcq","question":"Which optimizer is known for adaptive learning rates?","options":["SGD","Adam","RMSProp","GradientDescent"],"correct_index":1,"explanation":"Adam adapts learning rates based on first and second moments."}
{"type":"fill_blank","question":"The MNIST dataset contains images of handwritten ________.","answer":"digits","explanation":"MNIST consists of 28×28 grayscale handwritten digit images."}
{"type":"scenario","question":"You train an MNIST digit classifier but training accuracy is low. What is the first thing to try?","answer":"Increase number of epochs or adjust learning rate.","explanation":"Underfitting suggests insufficient training or learning rate issues."}
{"type":"mcq","question":"What does each pixel in a grayscale image represent?","options":["A color name","A number representing intensity","A text label","An RGB tuple"],"correct_index":1,"explanation":"Grayscale images store a single numeric intensity per pixel."}
{"type":"mcq","question":"How many channels does an RGB image have?","options":["1","2","3","4"],"correct_index":2,"explanation":"RGB has 3 color channels: Red, Green, Blue."}
{"type":"true_false","question":"A kernel (or filter) in computer vision is typically a small matrix that slides over an image to extract features.","options":["True","False"],"correct_index":0,"explanation":"Kernels perform convolution to detect edges, blur, etc."}
{"type":"mcq","question":"What does a 3x3 edge detection filter typically do?","options":["Increase brightness","Detect sudden changes in pixel values","Resize the image","Convert grayscale to RGB"],"correct_index":1,"explanation":"Edge filters highlight areas of intensity change."}
{"type":"coding_logic","question":"If a 5x5 image is convolved with a 3x3 filter using 'valid' padding and stride 1, what will be the output size?","options":["5x5","3x3","4x4","2x2"],"correct_index":1,"explanation":"Valid padding reduces output to (5-3+1)x(5-3+1)=3x3."}
{"type":"mcq","question":"What is the main purpose of pooling layers in CNNs?","options":["Increase resolution","Reduce spatial dimensions and computation","Convert images to grayscale","Add more channels"],"correct_index":1,"explanation":"Pooling compresses feature maps to make models efficient."}
{"type":"true_false","question":"Max pooling retains the largest value in each region of the feature map.","options":["True","False"],"correct_index":0,"explanation":"Max pooling selects the strongest activation per window."}
{"type":"mcq","question":"What does stride=2 in convolution mean?","options":["Apply filter twice","Move filter two pixels at a time","Double output channels","Double image size"],"correct_index":1,"explanation":"Stride controls how far the filter moves per step."}
{"type":"fill_blank","question":"In a CNN, the first layers usually learn _______ features, such as edges and textures.","answer":"low-level","explanation":"Early layers detect simple visual patterns."}
{"type":"mcq","question":"Which layer is commonly used at the end of a CNN for classification?","options":["Conv2D","Dense (Fully Connected)","MaxPooling2D","BatchNormalization"],"correct_index":1,"explanation":"Dense layers perform final classification after flattening."}
{"type":"true_false","question":"Convolutional layers share weights across spatial locations to reduce parameter count.","options":["True","False"],"correct_index":0,"explanation":"Weight sharing enables efficient pattern detection."}
{"type":"mcq","question":"Which of the following is TRUE about transfer learning in computer vision?","options":["Always trains from scratch","Uses pre-trained CNN models like ResNet or VGG","Only works on grayscale images","Cannot be used for small datasets"],"correct_index":1,"explanation":"Pre-trained models provide strong visual features."}
{"type":"mcq","question":"Why is transfer learning useful?","options":["It reduces training time and requires less data","It always increases image size","It eliminates the need for convolution","It works only with audio data"],"correct_index":0,"explanation":"Transfer learning reuses learned features to accelerate convergence."}
{"type":"fill_blank","question":"Convolution is a mathematical operation that combines an input image with a ________.","answer":"kernel","explanation":"Kernel or filter extracts new representations."}
{"type":"mcq","question":"Which padding type keeps the output feature map the same size as the input?","options":["Valid padding","Same padding","Zero cropping","No padding"],"correct_index":1,"explanation":"Same padding adds zeros to maintain size."}
{"type":"true_false","question":"A CNN can handle raw tabular data directly without preprocessing.","options":["True","False"],"correct_index":1,"explanation":"CNNs require image-like structures (spatial layout)." }
{"type":"mcq","question":"Which of the following tasks is best suited for CNNs?","options":["Text sentiment classification","Image classification","Sorting arrays","Linear regression"],"correct_index":1,"explanation":"CNNs specialize in spatial pattern recognition in images."}
{"type":"mcq","question":"What does the Flatten layer do in a CNN architecture?","options":["Adds more channels","Transforms feature maps into a 1D vector","Performs convolution","Removes pooling"],"correct_index":1,"explanation":"Flatten reshapes 2D outputs for Dense layers."}
{"type":"scenario","question":"A model misclassifies cats as dogs because their fur textures are similar. Which layer likely captures this confusion?","answer":"Early convolutional layers (low-level textures).","explanation":"Texture similarity affects low-level filters."}
{"type":"mcq","question":"Which visualization technique can show which pixels influence model predictions most?","options":["Scatter plot","Heatmap (Grad-CAM)","Histogram","Box plot"],"correct_index":1,"explanation":"Grad-CAM highlights important image regions."}
{"type":"fill_blank","question":"Pooling layers reduce the ________ cost of CNNs by shrinking feature maps.","answer":"computational","explanation":"Smaller feature maps reduce computation."}
{"type":"true_false","question":"ResNet uses skip connections to prevent vanishing gradients in deep networks.","options":["True","False"],"correct_index":0,"explanation":"Skip connections help gradients flow backwards effectively."}
{"type":"mcq","question":"Which filter detects vertical edges?","options":["[[1,1,1],[0,0,0],[-1,-1,-1]]","[[1,0,-1],[1,0,-1],[1,0,-1]]","[[0,0,0],[1,1,1],[0,0,0]]","[[1,-1,1],[-1,1,-1],[1,-1,1]]"],"correct_index":1,"explanation":"This kernel highlights differences in vertical direction."}
{"type":"coding_logic","question":"If input feature map is 32x32 and pooling is 2x2 with stride 2, what is the output size?","options":["32x32","16x16","8x8","2x2"],"correct_index":1,"explanation":"Pooling halves spatial dimensions: 32/2 = 16."}
{"type":"scenario","question":"You apply a 3x3 filter with stride 1 and SAME padding to a 28x28 image. What is the output size?","answer":"28x28","explanation":"SAME padding preserves original spatial dimensions."}
{"type":"mcq","question":"What is the primary goal of data augmentation in computer vision?","options":["Increase model size","Improve generalization by creating varied training samples","Reduce dataset size","Remove noise completely"],"correct_index":1,"explanation":"Augmentation improves robustness by artificially expanding data."}
{"type":"true_false","question":"Random horizontal flipping is a common augmentation technique for image classification.","options":["True","False"],"correct_index":0,"explanation":"Horizontal flips are widely used to simulate perspective variation."}
{"type":"mcq","question":"Which operation is considered a form of data augmentation?","options":["Max pooling","Image rotation","Weight decay","Batch normalization"],"correct_index":1,"explanation":"Augmentation modifies training inputs, such as rotations or flips."}
{"type":"mcq","question":"What does fine-tuning a pre-trained CNN involve?","options":["Training all layers from scratch","Only adjusting the final classification layers","Replacing convolution with LSTM","Removing ReLU"],"correct_index":1,"explanation":"Fine-tuning updates higher layers while lower layers retain general features."}
{"type":"true_false","question":"Freezing lower layers during transfer learning helps preserve generic feature extraction.","options":["True","False"],"correct_index":0,"explanation":"Lower layers capture edges/textures which are often reusable."}
{"type":"mcq","question":"Which of the following helps models handle images of different resolutions?","options":["Resizing inputs to a fixed shape","Deleting large images","Removing pixels","Converting to grayscale only"],"correct_index":0,"explanation":"CNNs expect consistent input dimensions."}
{"type":"fill_blank","question":"In object detection, the rectangle drawn around an object is called a ________ box.","answer":"bounding","explanation":"Bounding boxes indicate detected object areas."}
{"type":"mcq","question":"If the Intersection over Union (IoU) between a predicted box and ground truth is 0.8, how is the prediction classified? (Assuming IoU threshold is 0.5)","options":["True Positive","False Positive","True Negative","Ignored"],"correct_index":0,"explanation":"IoU ≥ threshold means a correct detection."}
{"type":"coding_logic","question":"Given IoU = 0.3 and a threshold of 0.5, is this detection accepted?","options":["Yes","No"],"correct_index":1,"explanation":"IoU below threshold means a false positive or miss."}
{"type":"mcq","question":"What is the key difference between image classification and object detection?","options":["Classification labels whole image, detection locates objects within image","Detection predicts only one class","Classification needs bounding boxes","Detection ignores features"],"correct_index":0,"explanation":"Detection localizes objects, not just labels."}
{"type":"true_false","question":"Image segmentation assigns a label to each pixel in an image.","options":["True","False"],"correct_index":0,"explanation":"Segmentation provides pixel-level classification."}
{"type":"mcq","question":"Which segmentation type assigns multiple labels within an image?","options":["Binary segmentation","Semantic segmentation","K-Means segmentation","PCA segmentation"],"correct_index":1,"explanation":"Semantic segmentation differentiates multiple regions."}
{"type":"mcq","question":"Which model is commonly used for image segmentation?","options":["ResNet-50","U-Net","MobileNet","Decision Tree"],"correct_index":1,"explanation":"U-Net is widely used for medical and spatial segmentation tasks."}
{"type":"mcq","question":"What risk exists when deploying facial recognition AI in surveillance?","options":["It always improves accuracy","It can lead to bias and misidentification","It cannot run on mobile devices","It replaces all human security staff"],"correct_index":1,"explanation":"Biased model training can lead to unfair misclassification."}
{"type":"fill_blank","question":"The process of randomly removing pixels or adding noise to improve robustness is called ________ augmentation.","answer":"noise","explanation":"Noise injection improves model tolerance."}
{"type":"true_false","question":"Data augmentation should also be applied to the validation/test set.","options":["True","False"],"correct_index":1,"explanation":"Augmentation is only applied to training data to avoid bias in evaluation."}
{"type":"mcq","question":"Which of the following is a common evaluation metric in object detection?","options":["Precision only","Mean Average Precision (mAP)","R² Score","RMSE"],"correct_index":1,"explanation":"mAP computes average precision across IoU thresholds."}
{"type":"mcq","question":"Which of the following best describes fine-tuning vs training from scratch?","options":["Fine-tuning requires more data than scratch","Fine-tuning is faster and uses pre-trained weights","Training from scratch always performs better","Fine-tuning removes convolution layers"],"correct_index":1,"explanation":"Fine-tuning reuses learned patterns for new tasks."}
{"type":"scenario","question":"You notice your object detection model detects random objects in empty backgrounds. What should you adjust?","answer":"Increase IoU threshold or add negative background samples.","explanation":"False positives occur when threshold is too low or background unbalanced."}
{"type":"mcq","question":"Which of the following data augmentations is most suitable for handwritten digit images?","options":["Color jitter","Horizontal flip","Minor rotation","Gaussian blur"],"correct_index":2,"explanation":"Digits can be rotated slightly without losing meaning."}
{"type":"true_false","question":"Increasing rotation angle to 180° is safe for all image classes.","options":["True","False"],"correct_index":1,"explanation":"Some classes (e.g., numbers, faces) lose meaning when fully flipped."}
{"type":"mcq","question":"Which of the following helps models generalize to different lighting conditions?","options":["Cropping","Brightness adjustment","Max pooling","Label smoothing"],"correct_index":1,"explanation":"Brightness changes simulate illumination variations."}
{"type":"fill_blank","question":"________ Learning is when a model pre-trained on ImageNet is adapted to a smaller dataset.","answer":"Transfer","explanation":"Transfer learning reuses learned features."}
{"type":"mcq","question":"What is the main advantage of using pretrained models for small datasets?","options":["They prevent overfitting by leveraging prior knowledge","They eliminate the need for any training","They automatically annotate data","They only work for grayscale inputs"],"correct_index":0,"explanation":"Pretrained weights help with limited data."}
{"type":"scenario","question":"In your final project, you trained a fruit classifier with 99% training accuracy but only 60% test accuracy. What is likely the cause?","answer":"Overfitting due to insufficient regularization or augmentation.","explanation":"High train vs low test accuracy indicates lack of generalization."}
{"type":"mcq","question":"Which AI application is MOST appropriate for machine learning rather than rules?","options":["Detecting spam emails","Computing factorial of n","Sorting a list","Checking if a number is prime"],"correct_index":0,"explanation":"Spam detection needs learned patterns from data; others are deterministic."}
{"type":"true_false","question":"AI, ML, and Deep Learning refer to identical concepts.","options":["True","False"],"correct_index":1,"explanation":"DL ⊂ ML ⊂ AI; they are related but not identical."}
{"type":"mcq","question":"Which step comes FIRST in the AI workflow?","options":["Model training","Deployment","Data collection/understanding","Hyperparameter tuning"],"correct_index":2,"explanation":"You must gather and understand data before training."}
{"type":"mcq","question":"Why is Python favored in AI prototyping?","options":["Fastest compiled speed","Rich ML ecosystem and readability","Mandatory by all clouds","Strongest static typing"],"correct_index":1,"explanation":"Libraries like NumPy, Pandas, scikit-learn, PyTorch, Keras enable fast iteration."}
{"type":"fill_blank","question":"In supervised learning, examples are pairs of features and ________.","answer":"labels","explanation":"Labels provide the target outputs for training."}
{"type":"true_false","question":"Colab notebooks allow GPU-backed interactive experiments in the browser.","options":["True","False"],"correct_index":0,"explanation":"Colab offers hosted Python with optional GPU/TPU runtimes."}
{"type":"mcq","question":"Which is MOST likely a regression problem?","options":["Predicting house price","Classifying spam","Clustering news topics","Detecting faces"],"correct_index":0,"explanation":"House price is a continuous numeric prediction."}
{"type":"mcq","question":"Which library provides tabular data structures like DataFrame?","options":["NumPy","Pandas","Matplotlib","Requests"],"correct_index":1,"explanation":"Pandas offers Series and DataFrame for tabular data."}
{"type":"true_false","question":"Better feature engineering can improve performance without changing the algorithm.","options":["True","False"],"correct_index":0,"explanation":"Quality features often drive model accuracy more than algorithm choice."}
{"type":"mcq","question":"Which task is LEAST suitable for ML?","options":["Digit recognition","Rule-based date formatting","Anomaly detection","Language translation"],"correct_index":1,"explanation":"Formatting dates is deterministic and rule-based."}
{"type":"fill_blank","question":"The step where a trained model is exposed for real use is ________.","answer":"deployment","explanation":"Deployment serves predictions via apps/APIs."}
{"type":"mcq","question":"Which statement is TRUE about datasets?","options":["More data always hurts","Balanced, representative data helps generalization","Labels aren’t necessary","Shuffling is harmful"],"correct_index":1,"explanation":"Representative datasets reduce bias and improve generalization."}
{"type":"true_false","question":"Deep learning always beats classical ML for small tabular data.","options":["True","False"],"correct_index":1,"explanation":"Tree-based models often win on small tabular datasets."}
{"type":"mcq","question":"Which evaluation aligns BEST with a classifier?","options":["RMSE","MAE","Accuracy","R²"],"correct_index":2,"explanation":"Accuracy is common for classification; RMSE/MAE/R² for regression."}
{"type":"mcq","question":"A minimal project kickoff in Colab should FIRST:","options":["Tune learning rate","Import libraries and inspect data","Deploy to production","Write UI code"],"correct_index":1,"explanation":"Start with imports and exploratory data analysis."}
{"type":"mcq","question":"Supervised learning is characterized by:","options":["No labels available","Rewards and environment","Input–output pairs for training","Random exploration only"],"correct_index":2,"explanation":"Supervised learning uses labeled examples to learn mappings."}
{"type":"true_false","question":"Clustering requires pre-labeled examples.","options":["True","False"],"correct_index":1,"explanation":"Clustering is unsupervised; it discovers structure in unlabeled data."}
{"type":"mcq","question":"Which learning type fits game playing via rewards?","options":["Supervised","Unsupervised","Reinforcement","Semi-supervised"],"correct_index":2,"explanation":"Reinforcement learning optimizes cumulative reward via environment interaction."}
{"type":"fill_blank","question":"Splitting data into training and ________ helps estimate generalization.","answer":"testing","explanation":"A test set estimates performance on unseen data."}
{"type":"true_false","question":"In regression, R² measures explained variance.","options":["True","False"],"correct_index":0,"explanation":"R² indicates how much variance the model explains."}
{"type":"mcq","question":"Which tool loads toy datasets in scikit-learn?","options":["sklearn.datasets","sklearn.metrics","sklearn.linear_model","sklearn.tree"],"correct_index":0,"explanation":"sklearn.datasets provides loaders like iris, boston, california_housing."}
{"type":"mcq","question":"Which is a classification label example?","options":["Price","Temperature","Spam = {0,1}","Height"],"correct_index":2,"explanation":"Classification predicts discrete classes (e.g., spam vs not-spam)."}
{"type":"true_false","question":"EDA (exploratory data analysis) should precede model training.","options":["True","False"],"correct_index":0,"explanation":"EDA uncovers data issues and informs modeling choices."}
{"type":"mcq","question":"Which task suits clustering?","options":["Grouping customers by behavior","Predicting stock price","Converting Celsius to Fahrenheit","Exact string matching"],"correct_index":0,"explanation":"Clustering groups similar items without labels."}
{"type":"fill_blank","question":"The umbrella field encompassing ML and DL is ________.","answer":"Artificial Intelligence","explanation":"AI includes ML and DL approaches."}
{"type":"mcq","question":"Linear regression is used to:","options":["Predict categories","Predict continuous values","Cluster points","Generate rewards"],"correct_index":1,"explanation":"Linear regression targets numeric outputs."}
{"type":"true_false","question":"Hold-out validation is an alternative to cross-validation.","options":["True","False"],"correct_index":0,"explanation":"Hold-out uses one split; CV averages across folds."}
{"type":"mcq","question":"In scikit-learn, which splits datasets?","options":["train_test_split","split_train","divide_data","data_splitter"],"correct_index":0,"explanation":"train_test_split in sklearn.model_selection handles splits."}
{"type":"mcq","question":"Which is NOT a supervised task?","options":["Image labeling","Spam detection","House price estimation","Topic discovery"],"correct_index":3,"explanation":"Topic discovery is unsupervised (clustering)."}
{"type":"true_false","question":"Balanced classes help accuracy be more meaningful.","options":["True","False"],"correct_index":0,"explanation":"Imbalance can make accuracy misleading; other metrics help."}
{"type":"mcq","question":"Predicting rainfall amount (mm) is:","options":["Classification","Clustering","Regression","Association"],"correct_index":2,"explanation":"It’s a continuous target; regression applies."}
{"type":"true_false","question":"Feature scaling is irrelevant to distance-based models.","options":["True","False"],"correct_index":1,"explanation":"KNN/K-Means rely on distances; scaling is important."}
{"type":"mcq","question":"Which is TRUE about overfitting?","options":["Always desirable","Happens when model memorizes noise","Guarantees great test accuracy","Caused by small train error and small test error"],"correct_index":1,"explanation":"Overfitting fits noise; generalization suffers."}
{"type":"mcq","question":"R² close to 1.0 indicates:","options":["Poor fit","Good variance explanation","Random model","Label leakage"],"correct_index":1,"explanation":"Higher R² means more variance explained by the model."}
{"type":"true_false","question":"Unsupervised learning can assist feature engineering for supervised tasks.","options":["True","False"],"correct_index":0,"explanation":"Clustering/PCA can create informative features."}
{"type":"mcq","question":"Which pairing is correct?","options":["Classification→MSE","Regression→R²","Clustering→Accuracy","RL→Confusion matrix"],"correct_index":1,"explanation":"R² is a common regression metric."}
{"type":"fill_blank","question":"A reduced, representative dataset used to iterate quickly is a data ________.","answer":"sample","explanation":"Sampling accelerates prototyping before scaling."}
{"type":"mcq","question":"Which step combats data leakage?","options":["Scale before splitting","Fit scalers on train only","Shuffle only test set","Use labels in features"],"correct_index":1,"explanation":"Fit preprocessing on train; apply to validation/test."}
{"type":"true_false","question":"Random_state ensures reproducible splits.","options":["True","False"],"correct_index":0,"explanation":"Setting random_state fixes RNG for deterministic results."}
{"type":"mcq","question":"Which is MOST likely a classification metric?","options":["Accuracy","MAE","RMSE","R²"],"correct_index":0,"explanation":"Accuracy evaluates correct class predictions."}
{"type":"mcq","question":"Label is also called:","options":["Feature","Target","Index","Row id"],"correct_index":1,"explanation":"Target/label is what we predict."}
{"type":"true_false","question":"Cross-validation reduces variance of performance estimates.","options":["True","False"],"correct_index":0,"explanation":"Averaging across folds stabilizes estimates."}
{"type":"mcq","question":"Which learning type fits anomaly detection without labels?","options":["Supervised","Unsupervised","Reinforcement","None"],"correct_index":1,"explanation":"Unsupervised algorithms can flag outliers without labels."}
{"type":"fill_blank","question":"Transforming raw inputs into informative variables is ________ engineering.","answer":"feature","explanation":"Feature engineering derives better predictors from raw data."}
{"type":"mcq","question":"Which is NOT part of a standard ML pipeline?","options":["EDA","Modeling","Evaluation","3D printing"],"correct_index":3,"explanation":"3D printing is unrelated to ML pipelines."}
{"type":"true_false","question":"Learning curves can diagnose under/overfitting.","options":["True","False"],"correct_index":0,"explanation":"Train/test curves indicate bias–variance issues."}
{"type":"mcq","question":"Which scenario suggests unsupervised learning?","options":["Predict churn (yes/no)","Group customers by similarity","Estimate sales next month","Classify images of animals"],"correct_index":1,"explanation":"Grouping without labels uses clustering."}
{"type":"mcq","question":"train_test_split stratify parameter is useful when:","options":["Data are balanced","You want to keep class ratios consistent","You have no labels","You need faster training"],"correct_index":1,"explanation":"Stratification preserves label distribution across splits."}
{"type":"true_false","question":"Feature leakage inflates validation metrics unrealistically.","options":["True","False"],"correct_index":0,"explanation":"Leakage lets the model peek at answers; metrics overstate performance."}
{"type":"mcq","question":"Which best describes classification vs regression?","options":["Both output numbers","Both output classes","Classification→classes; Regression→numbers","Both unsupervised"],"correct_index":2,"explanation":"Classification outputs labels; regression outputs continuous values."}
{"type":"mcq","question":"Which method best evaluates generalization reliably?","options":["Train accuracy only","Test set kept separate","Manual inspection only","Training loss"],"correct_index":1,"explanation":"A held-out test set estimates real-world performance."}
{"type":"true_false","question":"Linear regression minimizes squared error by default.","options":["True","False"],"correct_index":0,"explanation":"Ordinary Least Squares minimizes sum of squared residuals."}
{"type":"mcq","question":"Which is NOT typical of unsupervised learning?","options":["Clustering","Dimensionality reduction","Label prediction","Anomaly detection"],"correct_index":2,"explanation":"Label prediction is supervised."}
{"type":"mcq","question":"Choosing k for K-Means can use:","options":["Elbow method","AUC","F1-score","R²"],"correct_index":0,"explanation":"Elbow plots inertia vs k to pick a knee point."}
{"type":"true_false","question":"PCA finds components maximizing variance.","options":["True","False"],"correct_index":0,"explanation":"Principal components capture directions of maximal variance."}
{"type":"mcq","question":"Which best differentiates supervised vs unsupervised?","options":["Supervised has labels; unsupervised doesn’t","Both require labels","Unsupervised uses rewards","Supervised is clustering"],"correct_index":0,"explanation":"Supervised learns from labeled input–output pairs."}
{"type":"fill_blank","question":"Mean of squared residuals in regression is called ________.","answer":"MSE","explanation":"Mean Squared Error measures average squared prediction error."}
{"type":"mcq","question":"Which can cause underfitting?","options":["Model too simple","Too many parameters","Data leakage","Overly long training"],"correct_index":0,"explanation":"High bias (simple model) fails to capture patterns."}
{"type":"true_false","question":"Feature scaling should be fit on the entire dataset for fairness.","options":["True","False"],"correct_index":1,"explanation":"Fit on train only to avoid leaking test statistics."}
{"type":"mcq","question":"Which is TRUE about Random Forests?","options":["Single tree always better","They reduce variance via ensembling","They require feature scaling","They can’t handle categorical encodings"],"correct_index":1,"explanation":"Bagging multiple trees lowers variance and overfitting risk."}
{"type":"mcq","question":"Precision focuses on:","options":["TP over predicted positives","TP over actual positives","TN over all negatives","(TP+TN)/All"],"correct_index":0,"explanation":"Precision = TP/(TP+FP)."}
{"type":"true_false","question":"Recall is TP/(TP+FN).","options":["True","False"],"correct_index":0,"explanation":"Recall measures captured actual positives."}
{"type":"mcq","question":"Which is NOT a classification metric?","options":["Accuracy","F1-score","AUC","R²"],"correct_index":3,"explanation":"R² is for regression, not classification."}
{"type":"mcq","question":"A confusion matrix cell FP represents:","options":["True positives","False positives","True negatives","False negatives"],"correct_index":1,"explanation":"FP: predicted positive but actually negative."}
{"type":"fill_blank","question":"The harmonic mean of precision and recall is the ********.","answer":"F1-score","explanation":"F1-score balances precision and recall."}
{"type":"true_false","question":"Class imbalance can make accuracy misleading.","options":["True","False"],"correct_index":0,"explanation":"Accuracy can be high by predicting the majority class always."}
{"type":"mcq","question":"Decision boundary in logistic regression is typically at:","options":["p=0.1","p=0.5","p=0.9","p=1.0"],"correct_index":1,"explanation":"With equal costs, threshold 0.5 separates classes."}
{"type":"mcq","question":"Which hyperparameter most reduces overfitting in trees?","options":["Increase max_depth","Decrease max_depth","Increase features","No bootstrap"],"correct_index":1,"explanation":"Shallower trees generalize better."}
{"type":"true_false","question":"Random Forest uses bootstrap samples and random feature subsets.","options":["True","False"],"correct_index":0,"explanation":"Bagging with feature randomness improves diversity."}
{"type":"mcq","question":"Which situation prioritizes precision over recall?","options":["Cancer screening","Spam blocking to avoid blocking legit emails","Emergency detection","Fraud detection"],"correct_index":1,"explanation":"Avoid false positives that block legitimate emails."}
{"type":"mcq","question":"Which scikit-learn function computes ROC AUC?","options":["roc_auc_score","auc_roc_score","roc_score","auc_score"],"correct_index":0,"explanation":"Use sklearn.metrics.roc_auc_score."}
{"type":"true_false","question":"F1-score is high only when both precision and recall are high.","options":["True","False"],"correct_index":0,"explanation":"Harmonic mean penalizes imbalance between the two."}
{"type":"mcq","question":"Which regularization helps logistic regression generalize?","options":["L1/L2 penalties","More epochs only","Bigger learning rate","Dropout"],"correct_index":0,"explanation":"Penalizing weights reduces overfitting."}
{"type":"fill_blank","question":"Predicting all positives yields recall of ____****.","answer":"1","explanation":"No false negatives means recall = 1."}
{"type":"mcq","question":"Which ensemble usually reduces variance in classification?","options":["Bagging","Single deep tree","No bootstrap","Greedy pruning only"],"correct_index":0,"explanation":"Bagging (e.g., Random Forest) lowers variance."}
{"type":"true_false","question":"Calibration concerns how well probabilities reflect true likelihoods.","options":["True","False"],"correct_index":0,"explanation":"Well-calibrated models’ predicted probabilities match observed frequencies."}
{"type":"mcq","question":"Which approach handles missing labels best?","options":["Logistic regression","K-Means","SVM","Naive Bayes"],"correct_index":1,"explanation":"Clustering doesn’t need labels."}
{"type":"mcq","question":"Which encoding suits nominal categories?","options":["Label encoding","One-hot encoding","Ordinal mapping by rank","Hash only"],"correct_index":1,"explanation":"One-hot avoids imposing order on nominal categories."}
{"type":"true_false","question":"Median imputation is robust to outliers.","options":["True","False"],"correct_index":0,"explanation":"Median is less sensitive to extreme values than mean."}
{"type":"mcq","question":"Which scaler is most robust against outliers?","options":["MinMaxScaler","StandardScaler","RobustScaler","Normalizer"],"correct_index":2,"explanation":"RobustScaler uses median and IQR."}
{"type":"mcq","question":"Which Pandas call drops rows with any NaN?","options":["df.rmna()","df.dropna()","df.fillna()","df.clean()"],"correct_index":1,"explanation":"df.dropna() removes rows containing nulls."}
{"type":"fill_blank","question":"Creating features from timestamps (year, month, day) is ________ engineering.","answer":"feature","explanation":"Deriving new variables from raw data is feature engineering."}
{"type":"true_false","question":"Fit scalers on train then transform both train and test.","options":["True","False"],"correct_index":0,"explanation":"Prevents leakage of test statistics into training."}
{"type":"mcq","question":"High-cardinality categorical features after one-hot cause:","options":["Fewer columns","Sparser, wider matrices","No memory impact","Better interpretability"],"correct_index":1,"explanation":"Many unique categories create many sparse columns."}
{"type":"mcq","question":"Which detects multicollinearity among numeric features?","options":["ROC curves","Correlation matrix","Confusion matrix","Precision-Recall curve"],"correct_index":1,"explanation":"Correlation reveals feature interdependence."}
{"type":"true_false","question":"KNN imputation uses neighbor values to fill missing entries.","options":["True","False"],"correct_index":0,"explanation":"Nearest neighbors estimate reasonable replacements."}
{"type":"mcq","question":"Which is NOT a scaling technique?","options":["Standardization","Normalization","One-hot encoding","Robust scaling"],"correct_index":2,"explanation":"One-hot is encoding, not scaling."}
{"type":"fill_blank","question":"Removing duplicate rows uses df.************().","answer":"drop_duplicates","explanation":"drop_duplicates removes repeated entries."}
{"type":"mcq","question":"Which to do BEFORE scaling to avoid leakage?","options":["Split train/test first","Scale then split","Scale test only","Use test mean to scale train"],"correct_index":0,"explanation":"Split, then fit scalers only on the train set."}
{"type":"true_false","question":"Feature selection removes irrelevant/noisy features to improve generalization.","options":["True","False"],"correct_index":0,"explanation":"Selecting informative features can reduce overfitting."}
{"type":"mcq","question":"Which outlier treatment is MOST aggressive?","options":["Winsorizing","Clipping","Z-score filtering with strict threshold","Box-Cox transform"],"correct_index":2,"explanation":"Strict Z-score thresholds delete extreme points entirely."}
{"type":"mcq","question":"Silhouette score evaluates:","options":["Regression error","Cluster separation/cohesion","ROC curve quality","Overfitting depth"],"correct_index":1,"explanation":"Measures how similar a point is to its own cluster vs others."}
{"type":"true_false","question":"DBSCAN can mark points as noise (outliers).","options":["True","False"],"correct_index":0,"explanation":"Low-density points are labeled as noise."}
{"type":"mcq","question":"K-Means assumes clusters are:","options":["Arbitrary shapes","Spherical and similar size","Only one cluster","Hierarchical only"],"correct_index":1,"explanation":"K-Means partitions space into Voronoi cells around centroids."}
{"type":"mcq","question":"PCA primarily aims to:","options":["Maximize classes","Minimize distances","Capture maximal variance with fewer dimensions","Sort features"],"correct_index":2,"explanation":"Projects onto directions of greatest variance."}
{"type":"fill_blank","question":"Choosing k via inertia vs k plot is the ________ method.","answer":"elbow","explanation":"Look for the ‘knee’ where marginal gains drop."}
{"type":"true_false","question":"Applying PCA before clustering can reduce noise and speed up clustering.","options":["True","False"],"correct_index":0,"explanation":"Lower dimensions often help distance-based clustering."}
{"type":"mcq","question":"DBSCAN parameters include:","options":["n_estimators, max_depth","eps, min_samples","learning_rate, momentum","k, inertia"],"correct_index":1,"explanation":"eps and min_samples control density thresholds."}
{"type":"mcq","question":"Which metric is common for cluster validation without labels?","options":["Accuracy","Silhouette score","F1-score","AUC"],"correct_index":1,"explanation":"Silhouette uses cohesion and separation without labels."}
{"type":"true_false","question":"K-Means requires choosing k beforehand.","options":["True","False"],"correct_index":0,"explanation":"k (number of clusters) must be specified."}
{"type":"mcq","question":"High dimensionality can harm clustering due to:","options":["Curse of dimensionality","Extra labels appear","Better separability always","Guaranteed convergence"],"correct_index":0,"explanation":"Distances become less meaningful as dimensions grow."}
{"type":"fill_blank","question":"Points not assigned to any DBSCAN cluster are labeled as ________.","answer":"noise","explanation":"Insufficient local density marks points as noise."}
{"type":"mcq","question":"Which combination is valid for anomaly detection?","options":["K-Means distance thresholds","DBSCAN noise points","Both","Neither"],"correct_index":2,"explanation":"Both can surface unusual points."}
{"type":"true_false","question":"PCA components are orthogonal.","options":["True","False"],"correct_index":0,"explanation":"Orthogonality ensures uncorrelated principal components."}
{"type":"mcq","question":"t-SNE is mainly used for:","options":["Supervised classification","High-dimensional visualization","Linear regression","Time series forecasting"],"correct_index":1,"explanation":"t-SNE creates 2D/3D embeddings for visualization."}
{"type":"mcq","question":"Deep learning uses:","options":["Single-layer linear models","Multi-layer neural networks","Only decision trees","Only clustering"],"correct_index":1,"explanation":"Multiple nonlinear layers learn hierarchical representations."}
{"type":"true_false","question":"ReLU returns 0 for negative inputs.","options":["True","False"],"correct_index":0,"explanation":"ReLU(x)=max(0,x)."}
{"type":"mcq","question":"Softmax is typically used for:","options":["Binary output","Multi-class probabilities","Regression targets","Clustering labels"],"correct_index":1,"explanation":"Softmax converts logits to a class probability distribution."}
{"type":"mcq","question":"Which loss is common for multi-class classification?","options":["Binary cross-entropy","Categorical cross-entropy","MAE","MSE"],"correct_index":1,"explanation":"Categorical cross-entropy matches softmax outputs."}
{"type":"fill_blank","question":"Randomly zeroing activations during training to reduce overfitting is ________.","answer":"dropout","explanation":"Dropout discourages co-adaptation and overfitting."}
{"type":"true_false","question":"Batch size affects gradient estimate noise and update frequency.","options":["True","False"],"correct_index":0,"explanation":"Smaller batches yield noisier but more frequent updates."}
{"type":"mcq","question":"Which Keras API compiles models?","options":["model.fit","model.compile","model.build","model.save"],"correct_index":1,"explanation":"Compile specifies loss, optimizer, and metrics."}
{"type":"mcq","question":"Vanishing gradients are LESS severe with:","options":["Sigmoid everywhere","Tanh everywhere","ReLU in hidden layers","No activation"],"correct_index":2,"explanation":"ReLU keeps gradients for positive inputs."}
{"type":"true_false","question":"Early stopping halts training when validation stops improving.","options":["True","False"],"correct_index":0,"explanation":"Prevents overfitting by stopping at optimal epoch."}
{"type":"mcq","question":"Which optimizer adapts learning rates per parameter?","options":["SGD","Adam","Plain GD","Momentum only"],"correct_index":1,"explanation":"Adam uses first/second moment estimates for adaptation."}
{"type":"mcq","question":"Which indicates underfitting in NN training?","options":["High train, low test accuracy","Low train and low test accuracy","High test, low train","Train loss decreases, val loss decreases"],"correct_index":1,"explanation":"Low both suggests model too simple or insufficient training."}
{"type":"fill_blank","question":"Images in MNIST are ********×******** grayscale.","answer":"28×28","explanation":"MNIST digits are 28×28 pixel grayscale images."}
{"type":"true_false","question":"Normalization of inputs often accelerates deep network training.","options":["True","False"],"correct_index":0,"explanation":"Normalized inputs stabilize gradients and speed convergence."}
{"type":"mcq","question":"Which layer count roughly corresponds to ‘deep’ networks?","options":["1–2 layers","Many stacked layers","Only output layer","Only input layer"],"correct_index":1,"explanation":"Depth refers to multiple hidden layers."}
{"type":"mcq","question":"BatchNorm helps by:","options":["Labeling data","Normalizing activations within layers","Replacing loss","Reducing dataset size"],"correct_index":1,"explanation":"Stabilizes distributions, enabling higher learning rates."}
{"type":"true_false","question":"Weight decay is a form of L2 regularization.","options":["True","False"],"correct_index":0,"explanation":"L2 penalty shrinks weights to reduce overfitting."}
{"type":"mcq","question":"CNNs are best for:","options":["Tabular data","Sequential text","Spatial image data","Graph data"],"correct_index":2,"explanation":"Convolutions exploit local spatial structure."}
{"type":"mcq","question":"A 5×5 image convolved with 3×3 kernel, valid padding, stride 1 outputs:","options":["5×5","3×3","4×4","2×2"],"correct_index":1,"explanation":"(5−3+1)=3 per side → 3×3."}
{"type":"true_false","question":"Max pooling reduces spatial size by taking local maximums.","options":["True","False"],"correct_index":0,"explanation":"Pooling summarizes neighborhoods by a statistic."}
{"type":"mcq","question":"Stride 2 in convolution does what?","options":["Doubles channels","Moves filter 2 pixels per step","Removes padding","Upsamples feature maps"],"correct_index":1,"explanation":"Larger stride reduces output spatial dimensions."}
{"type":"fill_blank","question":"Weight sharing in convolutions reduces ________ count.","answer":"parameter","explanation":"Same kernel applied over positions lowers parameters."}
{"type":"true_false","question":"Transfer learning reuses features learned on large datasets.","options":["True","False"],"correct_index":0,"explanation":"Pretrained backbones speed convergence on small datasets."}
{"type":"mcq","question":"Which padding keeps output spatial size same as input?","options":["Valid","Same","Crop","Reflect only"],"correct_index":1,"explanation":"Same adds zeros to preserve dimensions."}
{"type":"mcq","question":"Grad-CAM is used to:","options":["Compress images","Explain model focus areas","Normalize inputs","Prune weights"],"correct_index":1,"explanation":"Highlights regions contributing to predictions."}
{"type":"true_false","question":"Flatten converts feature maps to 1D for Dense layers.","options":["True","False"],"correct_index":0,"explanation":"Flatten bridges conv features to fully connected layers."}
{"type":"mcq","question":"Which filter detects vertical edges?","options":["[[1,1,1],[0,0,0],[-1,-1,-1]]","[[1,0,-1],[1,0,-1],[1,0,-1]]","[[0,0,0],[1,1,1],[0,0,0]]","[[1,-1,1],[-1,1,-1],[1,-1,1]]"],"correct_index":1,"explanation":"Second kernel emphasizes vertical gradients."}
{"type":"mcq","question":"Why freeze early layers when fine-tuning?","options":["They hold generic features","They’re useless","They speed inference only","They block gradients forever"],"correct_index":0,"explanation":"Low-level edges/textures are general across tasks."}
{"type":"true_false","question":"ResNet skip connections help gradient flow in deep nets.","options":["True","False"],"correct_index":0,"explanation":"Shortcuts mitigate vanishing gradients."}
{"type":"mcq","question":"Which is BEST augmentation for viewpoint invariance?","options":["Horizontal flips/rotations","More epochs","Bigger batch size","Higher learning rate"],"correct_index":0,"explanation":"Spatial transforms simulate viewpoint changes."}
{"type":"mcq","question":"Object detection differs from classification by:","options":["Using bounding boxes to localize objects","Predicting a single label only","Ignoring spatial info","Not using CNNs"],"correct_index":0,"explanation":"Detection predicts class + location for each object."}
{"type":"true_false","question":"IoU measures overlap between predicted and ground-truth boxes.","options":["True","False"],"correct_index":0,"explanation":"Intersection over Union quantifies bounding box quality."}
{"type":"mcq","question":"If IoU=0.4 and threshold=0.5, the detection is:","options":["TP","FP or FN (rejected)","TN","Unknown"],"correct_index":1,"explanation":"Below threshold → not a true positive."}
{"type":"fill_blank","question":"Pixel-wise labeling of images is called image ________.","answer":"segmentation","explanation":"Each pixel is assigned a class label."}
{"type":"true_false","question":"Data augmentation should be applied to validation data to improve metrics.","options":["True","False"],"correct_index":1,"explanation":"Augment train only; keep validation/test distributions unchanged."}
{"type":"mcq","question":"mAP in detection aggregates:","options":["Average recall only","Average precision over classes/IoU thresholds","R² across classes","F1-score only"],"correct_index":1,"explanation":"Mean Average Precision summarizes precision-recall across settings."}
{"type":"mcq","question":"Which helps small datasets the MOST?","options":["Training from scratch","Transfer learning + fine-tuning","Removing regularization","Bigger output layer only"],"correct_index":1,"explanation":"Pretrained weights provide strong priors for limited data."}
{"type":"true_false","question":"Aggressive random crops can sometimes remove objects entirely.","options":["True","False"],"correct_index":0,"explanation":"Over-cropping may discard targets; use with caution."}
{"type":"mcq","question":"Which augmentation best simulates low-light conditions?","options":["Gaussian noise","Brightness reduction","Random rotation","Horizontal flip"],"correct_index":1,"explanation":"Brightness adjustments mimic illumination changes."}
{"type":"fill_blank","question":"Adapting a pretrained ImageNet model to a new task is ________ learning.","answer":"transfer","explanation":"Transfer learning reuses prior visual features."}
{"type":"mcq","question":"Which ethical risk is prominent in face recognition?","options":["Guaranteed fairness","Bias and disparate misidentification","Zero privacy concern","No deployment risk"],"correct_index":1,"explanation":"Biased datasets can harm protected groups."}
{"type":"true_false","question":"Fine-tuning higher layers while freezing early layers is common practice.","options":["True","False"],"correct_index":0,"explanation":"Adjust task-specific layers; preserve low-level features."}
{"type":"mcq","question":"If your detector flags many backgrounds as objects, first try:","options":["Lower IoU threshold","Raise IoU threshold or add background negatives","Remove all augmentations","Switch to grayscale"],"correct_index":1,"explanation":"Tighten criteria or balance training with hard negatives."}
{"type":"mcq","question":"Which deployment practice reduces inference latency?","options":["Add layers","Quantization/pruning","Disable batching","Use CPU only"],"correct_index":1,"explanation":"Model compression reduces computation and speeds inference."}
{"type":"true_false","question":"Test-time augmentation averages predictions over transformed test images.","options":["True","False"],"correct_index":0,"explanation":"TTA can improve robustness by ensembling transformed predictions."}
{"type":"mcq","question":"A classifier has 99% train and 60% test accuracy. Likely cause:","options":["Underfitting","Overfitting","Perfect generalization","Data leak on test"],"correct_index":1,"explanation":"Large train–test gap indicates overfitting; add regularization/augmentation."}
{"type":"mcq","question":"Which statement best defines supervised learning?","options":["Learning with labeled data","Learning from rewards only","Learning without labels","Learning by random search"],"correct_index":0,"explanation":"Supervised learning maps inputs to outputs using labeled examples."}
{"type":"true_false","question":"Deep Learning is a subset of Machine Learning.","options":["True","False"],"correct_index":0,"explanation":"DL ⊂ ML ⊂ AI."}
{"type":"mcq","question":"Which is MOST suitable for rule-based programming, not ML?","options":["Email spam detection","Optical character recognition","Parsing a fixed ID format","Speech recognition"],"correct_index":2,"explanation":"Fixed formats can be solved deterministically with rules."}
{"type":"fill_blank","question":"In a dataset, the variables used to make predictions are called ________.","answer":"features","explanation":"Features are input variables."}
{"type":"mcq","question":"Which task is regression?","options":["Predicting house price","Spam vs. not spam","Clustering articles","Topic modeling"],"correct_index":0,"explanation":"Price is continuous."}
{"type":"true_false","question":"Colab supports GPU runtimes for faster training.","options":["True","False"],"correct_index":0,"explanation":"Hardware accelerators can be enabled in Colab."}
{"type":"mcq","question":"Which scikit-learn utility loads example datasets?","options":["sklearn.datasets","sklearn.metrics","sklearn.svm","sklearn.pipeline"],"correct_index":0,"explanation":"Use sklearn.datasets for toy datasets."}
{"type":"mcq","question":"Which step should happen BEFORE model training?","options":["Hyperparameter search","EDA and data cleaning","Model deployment","A/B testing"],"correct_index":1,"explanation":"Understand and clean data first."}
{"type":"fill_blank","question":"The variable you aim to predict is the ________.","answer":"label","explanation":"Label/target is the output."}
{"type":"true_false","question":"Unsupervised learning can discover structure without labels.","options":["True","False"],"correct_index":0,"explanation":"Clustering and dimensionality reduction are unsupervised."}
{"type":"mcq","question":"Which metric is typical for classification?","options":["R²","Accuracy","RMSE","MAE"],"correct_index":1,"explanation":"Accuracy is for classification; others for regression."}
{"type":"mcq","question":"Which library is best for tabular data manipulation in Python?","options":["Pandas","OpenCV","NLTK","Requests"],"correct_index":0,"explanation":"Pandas provides DataFrame and Series."}
{"type":"true_false","question":"Better data quality can outperform switching algorithms.","options":["True","False"],"correct_index":0,"explanation":"Data quality heavily influences performance."}
{"type":"mcq","question":"Which task is NOT ML?","options":["Sorting numbers","Anomaly detection","Image classification","Machine translation"],"correct_index":0,"explanation":"Sorting is deterministic."}
{"type":"fill_blank","question":"Exposing a trained model via an API or app is ________.","answer":"deployment","explanation":"Deployment serves predictions to users."}
{"type":"mcq","question":"Which split proportion is common for simple hold-out validation?","options":["50/50","80/20","95/5","5/95"],"correct_index":1,"explanation":"80% train, 20% test is a common starting point."}
{"type":"true_false","question":"Cross-validation gives a more stable estimate than a single split.","options":["True","False"],"correct_index":0,"explanation":"Averages performance across folds."}
{"type":"mcq","question":"Which problem requires binary classification?","options":["Predicting rainfall amount","Detecting fraud vs. not fraud","Grouping users by behavior","Compressing images"],"correct_index":1,"explanation":"Two classes → binary classification."}
{"type":"mcq","question":"What is EDA primarily used for?","options":["Hyperparameter tuning","Model deployment","Understanding data patterns and issues","Containerization"],"correct_index":2,"explanation":"EDA inspects distributions, missingness, outliers."}
{"type":"fill_blank","question":"Replacing missing numeric values with the median is called ________.","answer":"imputation","explanation":"Imputation fills missing entries."}
{"type":"true_false","question":"Label encoding is preferred for nominal categories.","options":["True","False"],"correct_index":1,"explanation":"One-hot encoding is safer for unordered categories."}
{"type":"mcq","question":"Which scaler maps features to [0,1]?","options":["StandardScaler","MinMaxScaler","RobustScaler","Normalizer"],"correct_index":1,"explanation":"MinMaxScaler rescales into a fixed range."}
{"type":"mcq","question":"Which method best handles extreme outliers during scaling?","options":["StandardScaler","MinMaxScaler","RobustScaler","No scaling"],"correct_index":2,"explanation":"RobustScaler uses median and IQR."}
{"type":"true_false","question":"Fit the scaler on the training set only to avoid leakage.","options":["True","False"],"correct_index":0,"explanation":"Then transform train/validation/test with the fitted scaler."}
{"type":"mcq","question":"Which encoding explodes dimensionality with high-cardinality features?","options":["One-hot encoding","Label encoding","Frequency encoding","Target encoding"],"correct_index":0,"explanation":"One-hot creates one column per category."}
{"type":"fill_blank","question":"df.dropna() in Pandas removes rows with ________ values.","answer":"missing","explanation":"dropna removes NaNs/None by default."}
{"type":"mcq","question":"Which is NOT feature scaling?","options":["Standardization","Normalization","One-hot encoding","Robust scaling"],"correct_index":2,"explanation":"One-hot is categorical encoding."}
{"type":"true_false","question":"KNN and K-Means benefit from feature scaling.","options":["True","False"],"correct_index":0,"explanation":"Distance-based methods require comparable scales."}
{"type":"mcq","question":"Which of the following increases risk of overfitting during preprocessing?","options":["Imputing median","Fitting scaler on full dataset","Stratified split","Removing duplicates"],"correct_index":1,"explanation":"Using full dataset statistics leaks information."}
{"type":"mcq","question":"What does the elbow method help determine?","options":["Learning rate","Number of clusters k","Train/test ratio","Batch size"],"correct_index":1,"explanation":"Elbow on inertia vs. k helps choose k."}
{"type":"true_false","question":"DBSCAN can find clusters of arbitrary shape and label noise points.","options":["True","False"],"correct_index":0,"explanation":"Density-based clustering handles irregular shapes."}
{"type":"mcq","question":"Which metric assesses clustering quality without labels?","options":["Accuracy","Silhouette score","Precision","Recall"],"correct_index":1,"explanation":"Silhouette balances cohesion and separation."}
{"type":"mcq","question":"Principal Component Analysis (PCA) aims to:","options":["Create labels","Maximize variance along orthogonal axes","Increase dimensionality","Cluster data"],"correct_index":1,"explanation":"PCA finds orthogonal directions with maximal variance."}
{"type":"fill_blank","question":"Choosing k in K-Means often uses the ________ method.","answer":"elbow","explanation":"Elbow finds diminishing returns point."}
{"type":"true_false","question":"PCA components are orthogonal to each other.","options":["True","False"],"correct_index":0,"explanation":"Orthogonality reduces redundancy."}
{"type":"mcq","question":"K-Means assumes clusters are:","options":["Hierarchical","Spherical and similar size","Single cluster only","Graph-based"],"correct_index":1,"explanation":"Voronoi partitions around centroids imply near-spherical clusters."}
{"type":"mcq","question":"Which is a common use of clustering in business?","options":["Spam filtering","Customer segmentation","Exact matching","Fixed parsing"],"correct_index":1,"explanation":"Grouping similar customers by behavior."}
{"type":"true_false","question":"Reducing dimensionality can help clustering by denoising.","options":["True","False"],"correct_index":0,"explanation":"Lower-dimensional representations can improve separability."}
{"type":"mcq","question":"Which activation is LEAST prone to vanishing gradients?","options":["Sigmoid","Tanh","ReLU","Step"],"correct_index":2,"explanation":"ReLU preserves gradients for positive inputs."}
{"type":"mcq","question":"Which layer is fully connected in Keras?","options":["Conv2D","Dense","MaxPooling2D","Flatten"],"correct_index":1,"explanation":"Dense implements affine transformation per neuron."}
{"type":"true_false","question":"Softmax is used for multi-class output probabilities.","options":["True","False"],"correct_index":0,"explanation":"Softmax outputs a normalized distribution."}
{"type":"mcq","question":"Which loss is typical for binary classification in neural nets?","options":["MAE","Binary cross-entropy","MSE only","Huber"],"correct_index":1,"explanation":"Binary cross-entropy fits sigmoid outputs."}
{"type":"fill_blank","question":"Randomly dropping units during training to regularize is called ________.","answer":"dropout","explanation":"Dropout reduces co-adaptation."}
{"type":"true_false","question":"Batch normalization stabilizes training by normalizing activations.","options":["True","False"],"correct_index":0,"explanation":"BN reduces internal covariate shift."}
{"type":"mcq","question":"Which optimizer adapts per-parameter learning rates?","options":["SGD","Adam","Plain GD","Nesterov only"],"correct_index":1,"explanation":"Adam uses first/second moment estimates."}
{"type":"mcq","question":"A sign of overfitting in NN training is:","options":["Train↑ Test↑","Train↑ Test↓","Train↓ Test↑","Train≈Test low"],"correct_index":1,"explanation":"High train, low test indicates memorization."}
{"type":"true_false","question":"Early stopping uses validation metrics to halt training.","options":["True","False"],"correct_index":0,"explanation":"Stops when validation stops improving."}
{"type":"mcq","question":"Which best describes a CNN?","options":["Learns from tabular only","Uses convolutional filters to capture spatial features","Requires handcrafted edge detectors only","Never uses pooling"],"correct_index":1,"explanation":"Convolutions learn spatial patterns."}
{"type":"mcq","question":"What does SAME padding do?","options":["Shrinks output","Keeps output spatial size equal to input","Upsamples","No padding"],"correct_index":1,"explanation":"Zero padding preserves dimensions with stride 1."}
{"type":"true_false","question":"Pooling reduces spatial size and computation.","options":["True","False"],"correct_index":0,"explanation":"Pooling down-samples features."}
{"type":"mcq","question":"Transfer learning commonly:","options":["Trains from scratch on small data","Reuses pretrained backbones and fine-tunes","Removes all convolution layers","Forbids freezing layers"],"correct_index":1,"explanation":"Leverage pretrained features and fine-tune on target data."}
{"type":"fill_blank","question":"IoU stands for Intersection over ________.","answer":"Union","explanation":"IoU = overlap area / union area of boxes."}
{"type":"true_false","question":"Segmentation assigns a class label to each pixel.","options":["True","False"],"correct_index":0,"explanation":"Pixel-wise classification."}
{"type":"mcq","question":"mAP in detection summarizes:","options":["Mean absolute percentage error","Mean average precision","Mean adjusted precision","Model average performance"],"correct_index":1,"explanation":"mAP averages precision across classes/IoU thresholds."}
{"type":"mcq","question":"If IoU=0.75 and threshold=0.5, the detection is:","options":["True Positive","False Positive","True Negative","Ignored"],"correct_index":0,"explanation":"Above threshold → TP."}
{"type":"true_false","question":"Aggressive random crops can remove objects, harming detection training.","options":["True","False"],"correct_index":0,"explanation":"Ensure objects remain visible after crops."}
{"type":"mcq","question":"Which augmentation improves viewpoint invariance most?","options":["Horizontal flips and small rotations","Brightness-only changes","Label smoothing","Batch size increase"],"correct_index":0,"explanation":"Spatial transforms simulate viewpoint change."}
{"type":"fill_blank","question":"In a confusion matrix, FN stands for ________ negatives.","answer":"false","explanation":"FN: actual positive predicted negative."}
{"type":"true_false","question":"Precision = TP/(TP+FP).","options":["True","False"],"correct_index":0,"explanation":"Measures correctness among predicted positives."}
{"type":"mcq","question":"Recall should be prioritized when:","options":["False positives are costly","False negatives are costly","Classes are perfectly balanced","Compute is limited"],"correct_index":1,"explanation":"Recall reduces missed positives (FN)."}
{"type":"mcq","question":"Which reduces tree overfitting?","options":["Increase max_depth","Decrease max_depth","Disable pruning","Use entire feature set per split"],"correct_index":1,"explanation":"Limiting depth/pruning improves generalization."}
{"type":"true_false","question":"Random Forests train trees on bootstrap samples with random feature subsets.","options":["True","False"],"correct_index":0,"explanation":"Bagging + feature randomness."}
{"type":"mcq","question":"Which curve plots TPR vs. FPR at varying thresholds?","options":["PR curve","ROC curve","Learning curve","Lift chart"],"correct_index":1,"explanation":"ROC visualizes trade-offs across thresholds."}
{"type":"fill_blank","question":"The harmonic mean of precision and recall is the ________.","answer":"F1-score","explanation":"Balances precision and recall."}
{"type":"true_false","question":"Class imbalance can inflate accuracy deceptively.","options":["True","False"],"correct_index":0,"explanation":"A naive majority-class predictor can appear accurate."}
{"type":"mcq","question":"Which is NOT a classification metric?","options":["Accuracy","F1-score","AUC","R²"],"correct_index":3,"explanation":"R² is for regression."}
{"type":"mcq","question":"Which is typical for hyperparameter tuning?","options":["Grid/random search with CV","Edit model after deployment only","Use test set for selection","Skip validation"],"correct_index":0,"explanation":"Tune hyperparameters with cross-validation, not the test set."}
{"type":"true_false","question":"One-hot encoding creates one binary column per category.","options":["True","False"],"correct_index":0,"explanation":"Each category becomes an indicator column."}
{"type":"mcq","question":"Which method detects multicollinearity?","options":["Confusion matrix","Correlation heatmap","ROC curve","Precision-Recall curve"],"correct_index":1,"explanation":"Correlations reveal linear dependencies."}
{"type":"fill_blank","question":"Removing repeated observations is df.________________().","answer":"drop_duplicates","explanation":"Removes duplicate rows."}
{"type":"true_false","question":"StandardScaler makes features mean 0 and variance 1.","options":["True","False"],"correct_index":0,"explanation":"Z-score standardization."}
{"type":"mcq","question":"Which regularization drives some weights exactly to zero?","options":["L1","L2","No penalty","Elastic Net without L1"],"correct_index":1,"explanation":"L1 (Lasso) yields sparsity; note: index 1 corresponds to 'L2'—correct to L1. HOWEVER ensure mapping: Change options -> ['L1','L2','No penalty','Elastic Net'] and keep index 0."}
{"type":"mcq","question":"Select the correct statement about L2 regularization.","options":["It sets many weights to zero","It shrinks weights but rarely to zero","It increases variance","It disables gradient descent"],"correct_index":1,"explanation":"L2 (Ridge) discourages large weights without sparsity."}
{"type":"true_false","question":"Feature selection can improve model interpretability.","options":["True","False"],"correct_index":0,"explanation":"Fewer, more relevant features are easier to explain."}
{"type":"mcq","question":"Which pipeline prevents leakage in scikit-learn?","options":["Manually fit scaler on full data","Use sklearn.pipeline with StandardScaler then model","Scale after cross-validation","Fit on test set"],"correct_index":1,"explanation":"Pipelines fit transforms only on training folds."}
{"type":"fill_blank","question":"In K-Means, cluster centers are called ________.","answer":"centroids","explanation":"Centroids represent mean of assigned points."}
{"type":"true_false","question":"DBSCAN requires specifying the number of clusters.","options":["True","False"],"correct_index":1,"explanation":"It derives clusters from density without k."}
{"type":"mcq","question":"If two clusters strongly overlap, which metric likely drops?","options":["Silhouette score","AUC","R²","Accuracy"],"correct_index":0,"explanation":"Poor separation reduces silhouette values."}
{"type":"mcq","question":"PCA often helps by:","options":["Adding noise","Reducing dimensions and denoising","Duplicating features","Creating labels"],"correct_index":1,"explanation":"Lower-dimensional projections capture most variance."}
{"type":"true_false","question":"t-SNE is mainly for visualization, not for downstream training.","options":["True","False"],"correct_index":0,"explanation":"It preserves local neighborhoods for plots, not linear transforms."}
{"type":"mcq","question":"Which activation is appropriate for output layer in multi-class single-label classification?","options":["Sigmoid","Softmax","ReLU","Linear"],"correct_index":1,"explanation":"Softmax outputs class probabilities that sum to 1."}
{"type":"fill_blank","question":"The smallest NN unit computing weighted sum + activation is a ________.","answer":"neuron","explanation":"Also called perceptron in simple form."}
{"type":"true_false","question":"Learning rate too high can cause divergence.","options":["True","False"],"correct_index":0,"explanation":"Steps overshoot minima."}
{"type":"mcq","question":"Which indicates underfitting?","options":["Train high, test low","Train low, test low","Train high, test high","Train≈test moderate-high"],"correct_index":1,"explanation":"Both low → model too simple or insufficient training."}
{"type":"mcq","question":"CNNs reduce parameters by:","options":["Weight sharing in convolutions","Adding more dense layers","Removing pooling","Using larger fully connected layers"],"correct_index":0,"explanation":"Same kernels slide across spatial locations."}
{"type":"true_false","question":"Max pooling selects the maximum value in each window.","options":["True","False"],"correct_index":0,"explanation":"Common pooling strategy."}
{"type":"mcq","question":"Which padding likely reduces border information loss?","options":["VALID","SAME","NONE","CROP"],"correct_index":1,"explanation":"SAME adds zeros to preserve edges."}
{"type":"fill_blank","question":"Bounding boxes in detection are typically represented as (x, y, ________, ________).","answer":"width, height","explanation":"Coordinates plus size parameters."}
{"type":"true_false","question":"Increasing IoU threshold usually reduces the number of true positives.","options":["True","False"],"correct_index":0,"explanation":"Stricter overlap requirement rejects more detections."}
{"type":"mcq","question":"Which is a typical segmentation architecture?","options":["ResNet-50 classifier head","U-Net","Random Forest","Logistic regression"],"correct_index":1,"explanation":"U-Net is designed for pixel-wise prediction."}
{"type":"mcq","question":"Which technique can speed up inference on edge devices?","options":["Quantization","Larger batch size only","More layers","Higher resolution inputs"],"correct_index":0,"explanation":"Quantization reduces precision and compute."}
{"type":"true_false","question":"Data augmentation is applied to training data, not validation/test sets.","options":["True","False"],"correct_index":0,"explanation":"Keep evaluation distribution unchanged."}
{"type":"mcq","question":"Which metric balances precision and recall?","options":["Accuracy","R²","F1-score","MSE"],"correct_index":2,"explanation":"F1-score is the harmonic mean of precision and recall."}
{"type":"fill_blank","question":"Precision focuses on the correctness of predicted ________.","answer":"positives","explanation":"It measures TP relative to predicted positives."}
{"type":"true_false","question":"ROC-AUC is threshold independent.","options":["True","False"],"correct_index":0,"explanation":"AUC integrates performance over all thresholds."}
{"type":"mcq","question":"Which approach is best to handle severe class imbalance?","options":["Ignore it","Stratified sampling, class weights, or resampling","Use accuracy only","Drop minority class"],"correct_index":1,"explanation":"Rebalancing and cost-sensitive learning help."}
{"type":"mcq","question":"Which evaluation should be reported for imbalanced binary classification?","options":["Accuracy only","Precision, Recall, F1-score, PR-AUC","MSE","R²"],"correct_index":1,"explanation":"These capture performance on minority class."}
{"type":"true_false","question":"Target leakage can occur if future information is included in training features.","options":["True","False"],"correct_index":0,"explanation":"It inflates apparent performance but fails in production."}
{"type":"mcq","question":"Which pipeline step order is correct?","options":["Scale→Split→Train","Split→Fit scaler on train→Transform→Train→Evaluate","Train→Split→Scale","Deploy→Train→Split"],"correct_index":1,"explanation":"Preprocessing must be fit on train only after splitting."}
{"type":"fill_blank","question":"The set of tunable settings that aren't learned from data are ________.","answer":"hyperparameters","explanation":"Examples: learning rate, depth, C, k, etc."}
{"type":"true_false","question":"Grid search tries combinations exhaustively; random search samples the space.","options":["True","False"],"correct_index":0,"explanation":"Two common HPO strategies."}
{"type":"mcq","question":"Which approach reduces variance of a high-variance model?","options":["Smaller dataset","Bagging/ensembles","Less regularization","Higher learning rate"],"correct_index":1,"explanation":"Averaging models stabilizes predictions."}
{"type":"mcq","question":"Which regularization term corresponds to weight decay?","options":["L1","L2","Elastic Net","None"],"correct_index":1,"explanation":"Weight decay equals L2 penalty."}
{"type":"true_false","question":"Standardization before PCA is generally recommended.","options":["True","False"],"correct_index":0,"explanation":"PCA is scale sensitive."}
{"type":"mcq","question":"K-Means will likely fail when clusters are:","options":["Spherical and similar variance","Linearly separable","Different densities and non-spherical","Well-separated"],"correct_index":2,"explanation":"Assumptions break with varying shapes/densities."}
{"type":"fill_blank","question":"In logistic regression, the decision boundary is often at probability ________.","answer":"0.5","explanation":"Default threshold splits classes."}
{"type":"true_false","question":"Precision increases when the model predicts fewer positives (more conservative).","options":["True","False"],"correct_index":0,"explanation":"Fewer positive predictions tend to reduce FP, raising precision (may lower recall)."}
{"type":"mcq","question":"Which is a valid reason to prefer PR curve over ROC?","options":["Balanced datasets","Interest in negative class","Focus on positive class performance under imbalance","Better visuals"],"correct_index":2,"explanation":"PR is informative when positives are rare."}
{"type":"mcq","question":"Which technique combats overfitting in deep nets?","options":["Data augmentation","Smaller dataset","Higher LR only","No validation"],"correct_index":0,"explanation":"Augmentation increases variety and robustness."}
{"type":"true_false","question":"F1-score equals 1 only when precision and recall both equal 1.","options":["True","False"],"correct_index":0,"explanation":"Harmonic mean reaches 1 only at (1,1)."}
{"type":"mcq","question":"Which object detection post-processing reduces duplicate boxes?","options":["Random sampling","Non-maximum suppression (NMS)","Pooling","BatchNorm"],"correct_index":1,"explanation":"NMS keeps the highest-scoring box per object."}
{"type":"fill_blank","question":"Assigning class labels to each pixel is semantic ________.","answer":"segmentation","explanation":"Semantic segmentation is pixel-level classification."}
{"type":"true_false","question":"R² can be negative for poor regression models.","options":["True","False"],"correct_index":0,"explanation":"Worse than predicting the mean yields negative R²."}
{"type":"mcq","question":"Which statement about Random Forests is TRUE?","options":["They require feature scaling","They average many de-correlated trees","They cannot handle missingness","They always outperform gradient boosting"],"correct_index":1,"explanation":"Bagging reduces variance by averaging diverse trees."}
{"type":"mcq","question":"Which helps detect data leakage early?","options":["Evaluate only on train","Use cross-validation and strict feature audits","Tune on test set","Shuffle labels"],"correct_index":1,"explanation":"CV and audits catch suspiciously high scores."}
{"type":"true_false","question":"In Keras, model.fit trains parameters to minimize loss.","options":["True","False"],"correct_index":0,"explanation":"fit performs optimization with backpropagation."}
{"type":"mcq","question":"Which is a downside of one-hot encoding for 100k unique categories?","options":["Better interpretability","Lower RAM use","High dimensionality and sparsity","Faster training"],"correct_index":2,"explanation":"Creates huge sparse matrices."}
{"type":"fill_blank","question":"The process of grouping similar observations without labels is ________.","answer":"clustering","explanation":"Unsupervised grouping by similarity."}
{"type":"true_false","question":"Gradient descent updates weights in the direction of negative gradient.","options":["True","False"],"correct_index":0,"explanation":"Moves to reduce loss."}
{"type":"mcq","question":"Which metric is threshold-independent and useful for probability ranking?","options":["Accuracy","ROC-AUC","Precision","Recall"],"correct_index":1,"explanation":"AUC measures ranking quality over thresholds."}
{"type":"mcq","question":"Which cross-validation is fastest but highest variance?","options":["K-fold (k=10)","Leave-one-out CV","Single hold-out","Stratified k-fold"],"correct_index":2,"explanation":"One split is fast but unstable."}
{"type":"true_false","question":"Outliers can distort mean-based imputation.","options":["True","False"],"correct_index":0,"explanation":"Median is more robust to outliers."}
{"type":"mcq","question":"Which layer converts 2D feature maps into a vector?","options":["Flatten","Conv2D","MaxPool2D","BatchNorm2D"],"correct_index":0,"explanation":"Flatten reshapes to 1D for Dense layers."}
{"type":"fill_blank","question":"Distance-based models rely on comparable ________ scales.","answer":"feature","explanation":"Scale features to avoid dominance."}
{"type":"true_false","question":"Silhouette score close to 1 implies well-separated clusters.","options":["True","False"],"correct_index":0,"explanation":"Near 1 = good separation; near 0 = overlapping clusters."}
{"type":"mcq","question":"Which method reduces dimensionality linearly?","options":["PCA","t-SNE","UMAP","SMOTE"],"correct_index":0,"explanation":"PCA is a linear projection method."}
{"type":"mcq","question":"Which is a correct pair for segmentation tasks?","options":["YOLO — instance segmentation","U-Net — semantic segmentation","LinearRegression — pixel labeling","SVM — anchor generation"],"correct_index":1,"explanation":"U-Net is common for semantic segmentation."}
{"type":"true_false","question":"Higher IoU thresholds generally reduce recall at fixed confidence thresholds.","options":["True","False"],"correct_index":0,"explanation":"Stricter matching criteria reject more detections."}
{"type":"mcq","question":"Which learning curve pattern indicates high variance?","options":["Train high, val low","Train low, val low","Both high and close","Both low and close"],"correct_index":0,"explanation":"Large gap implies overfitting/high variance."}
{"type":"fill_blank","question":"The ratio TP/(TP+FP) is called ________.","answer":"precision","explanation":"Precision measures correctness among predicted positives."}
{"type":"true_false","question":"Label smoothing can improve calibration for neural classifiers.","options":["True","False"],"correct_index":0,"explanation":"Reduces overconfident predictions."}
{"type":"mcq","question":"Which approach helps with tiny datasets in vision?","options":["Train very deep net from scratch","Transfer learning + heavy augmentation","Use only grayscale","No validation"],"correct_index":1,"explanation":"Pretrained features and augmentation mitigate data scarcity."}
{"type":"mcq","question":"Which detection metric counts a prediction as correct only if IoU exceeds threshold and class matches?","options":["mAP","R²","RMSE","Silhouette"],"correct_index":0,"explanation":"AP/mAP depends on IoU and classification correctness."}
{"type":"true_false","question":"Normalization and standardization are identical processes.","options":["True","False"],"correct_index":1,"explanation":"Normalization rescales range; standardization centers and scales variance."}
{"type":"mcq","question":"Which technique combats covariate shift between train and test?","options":["Collect more representative data","Ignore shift","Tune on test set","Lower learning rate only"],"correct_index":0,"explanation":"Better sampling and domain adaptation help."}
{"type":"fill_blank","question":"The set aside portion used only once at the end is the ________ set.","answer":"test","explanation":"Held-out final evaluation set."}
{"type":"true_false","question":"Using the test set to pick hyperparameters biases results upward.","options":["True","False"],"correct_index":0,"explanation":"Leads to optimistic, invalid estimates."}
{"type":"mcq","question":"Which tree parameter controls minimum samples required to split?","options":["max_depth","min_samples_split","n_estimators","criterion"],"correct_index":1,"explanation":"min_samples_split limits splits on small nodes."}
{"type":"mcq","question":"Which ensemble typically reduces bias more than bagging?","options":["Random Forest","Gradient Boosting","Bootstrap only","Averaging k-means"],"correct_index":1,"explanation":"Boosting focuses on correcting errors, reducing bias."}
{"type":"true_false","question":"Shuffling before splitting helps ensure randomness in train/test partitions.","options":["True","False"],"correct_index":0,"explanation":"Avoids order effects."}
{"type":"mcq","question":"Which kernel size is typical for first CNN layers on images?","options":["1×1 only","3×3","15×15","31×31"],"correct_index":1,"explanation":"3×3 balances locality and compute."}
{"type":"fill_blank","question":"In PCA, the first component captures the largest ________.","answer":"variance","explanation":"PC1 explains maximal variance."}
{"type":"true_false","question":"A perfectly calibrated classifier with predicted p=0.7 will be correct ~70% of the time on such cases.","options":["True","False"],"correct_index":0,"explanation":"Calibration aligns probabilities with outcomes."}
{"type":"mcq","question":"Which metric is best when positives are rare and we care about their ranking?","options":["ROC-AUC","PR-AUC","Accuracy","RMSE"],"correct_index":1,"explanation":"PR-AUC emphasizes performance on the positive class under imbalance."}
{"type":"mcq","question":"Which is a correct usage of StandardScaler in a pipeline?","options":["Fit on test to be fair","Fit on all data then split","Fit on train folds within CV","Don’t scale at all"],"correct_index":2,"explanation":"Fit scaler in each CV fold on the training partition only."}
{"type":"true_false","question":"Non-maximum suppression removes lower-scoring boxes that heavily overlap a higher-scoring one.","options":["True","False"],"correct_index":0,"explanation":"NMS reduces duplicate detections."}
{"type":"mcq","question":"Which is an effect of very large batch sizes?","options":["More frequent updates","Less noisy gradients, potential generalization drop","Higher regularization automatically","No effect"],"correct_index":1,"explanation":"Large batches reduce noise but may generalize worse."}
{"type":"fill_blank","question":"In logistic regression, the link function is the ________ (logistic) function.","answer":"sigmoid","explanation":"Maps logits to probabilities in (0,1)."}
{"type":"true_false","question":"One should stratify splits in classification to preserve class ratios.","options":["True","False"],"correct_index":0,"explanation":"Stratification maintains label distribution in each split."}
{"type":"mcq","question":"Which scenario prefers high precision over recall?","options":["Cancer screening","Blocking spam to avoid false blocks","Finding all fraud cases","Rescue alerts"],"correct_index":1,"explanation":"Precision avoids false positives that harm user experience."}
{"type":"mcq","question":"Which method can reduce model size for mobile deployment?","options":["Model distillation","More parameters","Higher resolution inputs","Longer training only"],"correct_index":0,"explanation":"Distillation transfers knowledge to a smaller student model."}
{"type":"true_false","question":"AUC=0.5 implies random ranking ability.","options":["True","False"],"correct_index":0,"explanation":"No better than random guessing."}
{"type":"mcq","question":"Which metric measures average squared prediction error?","options":["MAE","MSE","Accuracy","F1-score"],"correct_index":1,"explanation":"MSE is mean of squared residuals."}
{"type":"fill_blank","question":"Reducing learning rate when validation plateaus is LR ________.","answer":"scheduling","explanation":"LR schedules adjust step size over time."}
{"type":"true_false","question":"BatchNorm allows higher learning rates and faster convergence.","options":["True","False"],"correct_index":0,"explanation":"Stabilized activations permit more aggressive optimization."}
{"type":"mcq","question":"Which method transforms text categories without exploding dimensions?","options":["One-hot only","Label encoding for nominal","Hashing trick or target/frequency encoding","Creating thousands of columns"],"correct_index":2,"explanation":"Hashing/target/frequency manage high cardinality."}
{"type":"mcq","question":"Which is a sign of data leakage?","options":["Similar train and test performance","Unrealistically high CV scores that drop in production","Stable performance across folds","Consistent metrics with independent test"],"correct_index":1,"explanation":"Leakage inflates validation results but fails in production."}
{"type":"true_false","question":"A well-regularized model often has slightly higher bias and lower variance.","options":["True","False"],"correct_index":0,"explanation":"Regularization trades a bit of bias to reduce variance and improve generalization."}
{"type":"mcq","question":"Which CNN component reduces sensitivity to small translations?","options":["Convolution only","Pooling","Dropout","BatchNorm"],"correct_index":1,"explanation":"Pooling builds some translation invariance."}
{"type":"fill_blank","question":"An ML model’s settings chosen before training are called ________.","answer":"hyperparameters","explanation":"Not learned from data."}
{"type":"true_false","question":"PR-AUC is especially informative when the positive class is rare.","options":["True","False"],"correct_index":0,"explanation":"Focuses on precision/recall trade-offs for rare positives."}
{"type":"mcq","question":"Which validation strategy maximizes data usage for training while still validating?","options":["Hold-out only","k-fold cross-validation","Test set tuning","No validation"],"correct_index":1,"explanation":"Each fold trains on k−1 parts and validates on the remaining."}
{"type":"mcq","question":"Which preprocessing step should be learned on training splits only?","options":["Label creation","Standardization parameters","Shuffling indices","Metric calculation"],"correct_index":1,"explanation":"Fit scalers/encoders on train to avoid leakage."}
{"type":"true_false","question":"F1-score punishes extreme imbalance between precision and recall more than arithmetic mean.","options":["True","False"],"correct_index":0,"explanation":"Harmonic mean penalizes low values strongly."}
{"type":"mcq","question":"Which is typically used to explain CNN decisions visually?","options":["Grad-CAM","ROC curve","Elbow plot","Silhouette plot"],"correct_index":0,"explanation":"Grad-CAM highlights influential regions of the image."}
{"type":"fill_blank","question":"The area under the ROC curve is abbreviated as ________.","answer":"AUC","explanation":"AUC summarizes ROC performance."}
{"type":"true_false","question":"Instance segmentation distinguishes different objects of the same class.","options":["True","False"],"correct_index":0,"explanation":"Instance segmentation separates individual instances."}
{"type":"mcq","question":"Which step helps when the model misses small objects in detection?","options":["Increase input resolution or use feature pyramids","Lower learning rate only","Remove augmentation","Disable NMS"],"correct_index":0,"explanation":"Higher resolution and multi-scale features improve small-object recall."}
{"type":"mcq","question":"Which change usually improves recall but may hurt precision?","options":["Raise threshold","Lower threshold","Reduce training data","Increase weight decay"],"correct_index":1,"explanation":"Lowering threshold predicts positive more often."}
{"type":"true_false","question":"Elastic Net combines L1 and L2 penalties.","options":["True","False"],"correct_index":0,"explanation":"It blends sparsity and shrinkage."}
{"type":"mcq","question":"Which sign suggests underfitting in tree models?","options":["Very deep tree","Very shallow tree with high bias","Many trees in a forest","Using all features randomly"],"correct_index":1,"explanation":"Too shallow fails to capture complexity."}
{"type":"mcq","question":"Which statement best distinguishes AI vs. ML vs. DL?","options":["AI ⊃ ML ⊃ DL","AI ⊂ ML ⊂ DL","AI = ML = DL","ML ⊃ AI ⊃ DL"],"correct_index":0,"explanation":"Deep Learning is a subset of Machine Learning, which is a subset of AI."}
{"type":"true_false","question":"A rules-based program that formats dates is a good candidate for ML.","options":["True","False"],"correct_index":1,"explanation":"Deterministic formatting is solved with rules, not ML."}
{"type":"mcq","question":"Which task is MOST appropriate for ML?","options":["Converting Celsius to Fahrenheit","Email spam filtering","Calculating tax by fixed law","Sorting integers"],"correct_index":1,"explanation":"Spam detection benefits from learned patterns in data."}
{"type":"fill_blank","question":"The output variable in supervised learning is the ________.","answer":"label","explanation":"Also called target or y."}
{"type":"mcq","question":"Which is a classification problem?","options":["Predicting house price","Detecting fraudulent vs. legitimate transactions","Estimating temperature","Forecasting demand (units)"],"correct_index":1,"explanation":"Binary class decision vs. continuous values."}
{"type":"true_false","question":"EDA should precede modeling to uncover issues like missingness and outliers.","options":["True","False"],"correct_index":0,"explanation":"EDA informs cleaning and feature engineering."}
{"type":"mcq","question":"Which library primarily provides DataFrame operations?","options":["NumPy","Pandas","Matplotlib","Seaborn"],"correct_index":1,"explanation":"Pandas offers Series/DataFrame APIs."}
{"type":"mcq","question":"Which split is a common starting point?","options":["90/10","80/20","60/40","50/50"],"correct_index":1,"explanation":"80% train, 20% test is widely used initially."}
{"type":"true_false","question":"Cross-validation averages performance over folds to reduce variance.","options":["True","False"],"correct_index":0,"explanation":"CV stabilizes estimates compared to a single split."}
{"type":"fill_blank","question":"Deploying a trained model to serve predictions is called ________.","answer":"deployment","explanation":"Model is exposed via app/API for real use."}
{"type":"mcq","question":"Which metric fits regression?","options":["Accuracy","R²","Precision","Recall"],"correct_index":1,"explanation":"R² measures explained variance for regression."}
{"type":"mcq","question":"Which is NOT a benefit of Colab?","options":["Hosted GPUs","Python notebooks","Offline-only execution","Easy sharing"],"correct_index":2,"explanation":"Colab is cloud-hosted, not offline-only."}
{"type":"true_false","question":"Balanced datasets make accuracy more informative.","options":["True","False"],"correct_index":0,"explanation":"With imbalance, accuracy can be misleading."}
{"type":"mcq","question":"Which is typical for unsupervised learning?","options":["Label prediction","Clustering customers","Computing loan defaults directly","Supervised tuning"],"correct_index":1,"explanation":"Clustering discovers structure without labels."}
{"type":"fill_blank","question":"Input variables used by the model are called ________.","answer":"features","explanation":"Features x feed the algorithm to predict y."}
{"type":"mcq","question":"Train/test leakage occurs when:","options":["You split before scaling","Test statistics influence training","You use validation for tuning","You randomize splits"],"correct_index":1,"explanation":"Including test info in training inflates metrics."}
{"type":"true_false","question":"More data can improve model generalization if it’s representative.","options":["True","False"],"correct_index":0,"explanation":"Diverse, high-quality data aids learning."}
{"type":"mcq","question":"Which learning type fits game playing with rewards?","options":["Supervised","Unsupervised","Reinforcement","Self-supervised"],"correct_index":2,"explanation":"RL optimizes cumulative reward via environment interaction."}
{"type":"mcq","question":"Which tool splits data in scikit-learn?","options":["train_test_split","split_dataset","data_split","mk_split"],"correct_index":0,"explanation":"Located in sklearn.model_selection."}
{"type":"fill_blank","question":"Predicting continuous values is called ________.","answer":"regression","explanation":"Targets are numeric, not categorical."}
{"type":"true_false","question":"Linear regression minimizes sum of squared residuals under OLS.","options":["True","False"],"correct_index":0,"explanation":"OLS solution minimizes squared errors."}
{"type":"mcq","question":"Which is LEAST suited for ML?","options":["Language translation","Anomaly detection","Exact ISBN checksum validation","Image recognition"],"correct_index":2,"explanation":"Checksums are deterministic algorithms."}
{"type":"mcq","question":"Which is a label example?","options":["Email body","Spam ∈ {0,1}","Sender domain","Subject tokens"],"correct_index":1,"explanation":"Label is the target class."}
{"type":"true_false","question":"Shuffling before splitting helps prevent temporal leakage in random data.","options":["True","False"],"correct_index":0,"explanation":"Avoids accidental structure in splits."}
{"type":"fill_blank","question":"The practice of iteratively exploring and cleaning data is called ________.","answer":"EDA","explanation":"Exploratory data analysis."}
{"type":"mcq","question":"Which metric should NOT be used for classification?","options":["Accuracy","AUC","R²","F1-score"],"correct_index":2,"explanation":"R² is for regression, not classification."}
{"type":"mcq","question":"Which scenario is binary classification?","options":["Predict annual revenue","Spam vs. not spam","Group users by interest without labels","Forecast temperature"],"correct_index":1,"explanation":"Two mutually exclusive labels."}
{"type":"true_false","question":"Good features can outperform switching algorithms.","options":["True","False"],"correct_index":0,"explanation":"Feature quality often dominates algorithm choice."}
{"type":"mcq","question":"Which correctly defines precision?","options":["TP/(TP+FN)","TP/(TP+FP)","(TP+TN)/All","TN/(TN+FP)"],"correct_index":1,"explanation":"Precision measures correctness among predicted positives."}
{"type":"fill_blank","question":"Recall equals TP divided by TP plus ________.","answer":"FN","explanation":"Recall = TP/(TP+FN)."}
{"type":"true_false","question":"F1-score is the harmonic mean of precision and recall.","options":["True","False"],"correct_index":0,"explanation":"Balances both metrics."}
{"type":"mcq","question":"Which is NOT typically a classification metric?","options":["Accuracy","F1-score","ROC-AUC","RMSE"],"correct_index":3,"explanation":"RMSE is used for regression errors."}
{"type":"mcq","question":"A confusion matrix cell FP means:","options":["Predicted positive, actually negative","Predicted negative, actually positive","Predicted positive, actually positive","Predicted negative, actually negative"],"correct_index":0,"explanation":"False positive is a type I error."}
{"type":"true_false","question":"Class imbalance can make accuracy misleadingly high.","options":["True","False"],"correct_index":0,"explanation":"Predicting majority class can yield high accuracy while missing minority."}
{"type":"mcq","question":"Which action typically raises recall (at cost to precision)?","options":["Lower decision threshold","Raise decision threshold","Reduce dataset size","Increase regularization"],"correct_index":0,"explanation":"Predict positive more often → fewer FN, more FP."}
{"type":"fill_blank","question":"The default logistic regression decision threshold is ________.","answer":"0.5","explanation":"Equal costs imply threshold 0.5 on probability."}
{"type":"true_false","question":"Random Forest reduces variance via bagging and feature sub-sampling.","options":["True","False"],"correct_index":0,"explanation":"Ensembling decorrelates trees and averages errors."}
{"type":"mcq","question":"Which setting helps prevent tree overfitting?","options":["max_depth too large","max_depth constraint/pruning","no min_samples_split","no constraints"],"correct_index":1,"explanation":"Depth limits and pruning improve generalization."}
{"type":"mcq","question":"When to prioritize precision over recall?","options":["Cancer screening","Spam blocking to avoid false blocks","Rescue alerts","Fraud catching at all costs"],"correct_index":1,"explanation":"Avoiding false positives is key for user experience."}
{"type":"true_false","question":"ROC-AUC summarizes ranking across thresholds.","options":["True","False"],"correct_index":0,"explanation":"Threshold-independent measure of separability."}
{"type":"fill_blank","question":"Predicting all samples positive gives recall of ________.","answer":"1","explanation":"No FN → recall equals 1."}
{"type":"mcq","question":"Which preprocessing step should be fit ONLY on training data?","options":["Standardization parameters","Metric calculation","Random seed","Label reading"],"correct_index":0,"explanation":"Fit scalers/encoders on train to avoid leakage."}
{"type":"true_false","question":"Median imputation is more robust to outliers than mean imputation.","options":["True","False"],"correct_index":0,"explanation":"Median is less influenced by extremes."}
{"type":"mcq","question":"Which scaler maps features to [0,1]?","options":["StandardScaler","MinMaxScaler","RobustScaler","Normalizer"],"correct_index":1,"explanation":"MinMax scales to fixed range."}
{"type":"mcq","question":"Which encoding is safer for nominal categories?","options":["Label encoding","One-hot encoding","Ordinal mapping","Manual ranking"],"correct_index":1,"explanation":"One-hot doesn’t impose false order."}
{"type":"true_false","question":"KNN and K-Means benefit from scaling because they rely on distances.","options":["True","False"],"correct_index":0,"explanation":"Comparable feature scales improve distance computations."}
{"type":"fill_blank","question":"Removing repeated rows in Pandas uses df.________________().","answer":"drop_duplicates","explanation":"Eliminates duplicate observations."}
{"type":"mcq","question":"Which is NOT a scaling technique?","options":["Standardization","Normalization","Robust scaling","One-hot encoding"],"correct_index":3,"explanation":"One-hot encodes categories; it doesn’t scale numerics."}
{"type":"true_false","question":"Fit the scaler before splitting to use all data statistics.","options":["True","False"],"correct_index":1,"explanation":"This leaks test information; split first, fit on train only."}
{"type":"mcq","question":"Which helps detect collinearity among numeric features?","options":["Correlation matrix","Confusion matrix","ROC curve","PR curve"],"correct_index":0,"explanation":"Correlations reveal redundant features."}
{"type":"fill_blank","question":"Creating year, month, day from a timestamp is ________ engineering.","answer":"feature","explanation":"Deriving useful features from raw fields."}
{"type":"true_false","question":"KNN imputation fills missing values using nearest neighbors.","options":["True","False"],"correct_index":0,"explanation":"Uses neighbor patterns to estimate missing entries."}
{"type":"mcq","question":"Which outlier treatment is MOST conservative?","options":["Delete outliers immediately","Winsorize/clipping","Transform (log)","Ignore scaling"],"correct_index":2,"explanation":"Transforms reduce skew without discarding data."}
{"type":"mcq","question":"Which method helps choose k in K-Means?","options":["Elbow method","R²","AUC","MSE"],"correct_index":0,"explanation":"Elbow on inertia vs. k reveals diminishing returns."}
{"type":"true_false","question":"DBSCAN can discover non-spherical clusters and mark noise.","options":["True","False"],"correct_index":0,"explanation":"Density-based algorithm finds arbitrary shapes."}
{"type":"mcq","question":"Which metric evaluates cluster cohesion/separation?","options":["Silhouette score","Accuracy","Recall","F1-score"],"correct_index":0,"explanation":"Silhouette ∈ [-1,1] higher is better."}
{"type":"fill_blank","question":"PCA components are ________ to each other.","answer":"orthogonal","explanation":"Independent axes capture maximum variance."}
{"type":"true_false","question":"Applying PCA before clustering can reduce noise and speed up K-Means.","options":["True","False"],"correct_index":0,"explanation":"Lower dimensions improve distance meaning and efficiency."}
{"type":"mcq","question":"DBSCAN key parameters:","options":["eps and min_samples","k and inertia","alpha and lambda","depth and estimators"],"correct_index":0,"explanation":"eps sets neighborhood radius; min_samples defines density."}
{"type":"mcq","question":"Which scenario is an outlier signal in K-Means?","options":["Very small cluster far away","Equal-sized clusters","Centroids overlapping heavily","Perfect silhouette 1.0"],"correct_index":0,"explanation":"Isolated tiny clusters may indicate anomalies."}
{"type":"true_false","question":"The curse of dimensionality can degrade distance-based clustering.","options":["True","False"],"correct_index":0,"explanation":"Distances become less informative at high dimensions."}
{"type":"fill_blank","question":"In PCA, the first component maximizes explained ________.","answer":"variance","explanation":"PC1 captures the largest variance direction."}
{"type":"mcq","question":"Deep learning differs from traditional ML mainly by:","options":["Relying on hand-crafted features","Using multilayer representation learning","Not needing data","Being rule-based"],"correct_index":1,"explanation":"DL learns hierarchical features from data."}
{"type":"true_false","question":"ReLU outputs 0 for negative inputs and x for positive inputs.","options":["True","False"],"correct_index":0,"explanation":"ReLU(x)=max(0,x)."}
{"type":"mcq","question":"Which activation suits multi-class single-label output?","options":["Sigmoid","Softmax","ReLU","Tanh"],"correct_index":1,"explanation":"Softmax yields probabilities that sum to 1."}
{"type":"fill_blank","question":"Randomly zeroing activations during training is ________.","answer":"dropout","explanation":"Regularizes neural networks by discouraging co-adaptation."}
{"type":"true_false","question":"Batch normalization helps stabilize/accelerate training.","options":["True","False"],"correct_index":0,"explanation":"Normalizes layer activations across a batch."}
{"type":"mcq","question":"Which optimizer adapts per-parameter learning rates?","options":["SGD","Adam","Plain GD","Nesterov-only"],"correct_index":1,"explanation":"Adam uses first/second moment estimates."}
{"type":"mcq","question":"Which indicates underfitting in NN training?","options":["Train high/Test low","Train low/Test low","Train high/Test high","Train≈Test medium-high"],"correct_index":1,"explanation":"Both low → high bias."}
{"type":"true_false","question":"Early stopping halts when validation stops improving.","options":["True","False"],"correct_index":0,"explanation":"Prevents overfitting by selecting a good epoch."}
{"type":"fill_blank","question":"MNIST images are ********×******** grayscale.","answer":"28×28","explanation":"Standard digit dataset shape."}
{"type":"mcq","question":"Which Keras call sets loss, optimizer, metrics?","options":["model.fit","model.compile","model.predict","model.save"],"correct_index":1,"explanation":"Compile configures training."}
{"type":"true_false","question":"Normalization of inputs usually speeds deep network convergence.","options":["True","False"],"correct_index":0,"explanation":"Well-scaled data aids optimization."}
{"type":"mcq","question":"CNNs reduce parameters via:","options":["More dense layers","Weight sharing in convolutions","Random deletion of channels","Using larger kernels only"],"correct_index":1,"explanation":"Same kernel applies over spatial positions."}
{"type":"mcq","question":"Stride=2 in convolution does what?","options":["Upsamples","Moves filter two pixels per step","Adds channels","Increases padding"],"correct_index":1,"explanation":"Larger stride reduces spatial resolution."}
{"type":"true_false","question":"SAME padding preserves input size (stride 1).","options":["True","False"],"correct_index":0,"explanation":"Zero padding maintains spatial dimensions."}
{"type":"fill_blank","question":"Pooling primarily reduces ________ cost by downsampling.","answer":"computational","explanation":"Smaller feature maps cost less to process."}
{"type":"mcq","question":"Transfer learning is helpful because:","options":["It removes the need for data","It reuses generic features and shortens training","It always beats training from scratch","It forbids freezing layers"],"correct_index":1,"explanation":"Pretrained backbones accelerate learning on small data."}
{"type":"true_false","question":"Grad-CAM highlights image regions driving predictions.","options":["True","False"],"correct_index":0,"explanation":"A popular explainability technique for CNNs."}
{"type":"mcq","question":"Which kernel detects vertical edges?","options":["[[1,1,1],[0,0,0],[-1,-1,-1]]","[[1,0,-1],[1,0,-1],[1,0,-1]]","[[0,0,0],[1,1,1],[0,0,0]]","[[1,-1,1],[-1,1,-1],[1,-1,1]]"],"correct_index":1,"explanation":"Second kernel emphasizes vertical gradients."}
{"type":"fill_blank","question":"Weight sharing in CNNs reduces ________ count.","answer":"parameter","explanation":"Fewer trainable weights than dense layers."}
{"type":"true_false","question":"ResNet skip connections improve gradient flow in deep nets.","options":["True","False"],"correct_index":0,"explanation":"Helps mitigate vanishing gradients."}
{"type":"mcq","question":"Which augmentation most improves viewpoint invariance?","options":["Horizontal flips/rotations","Higher learning rate","More epochs only","BatchNorm"],"correct_index":0,"explanation":"Spatial transforms simulate camera changes."}
{"type":"mcq","question":"Object detection differs from classification by:","options":["Ignoring spatial info","Classifying whole image only","Predicting class + bounding box","Requiring grayscale inputs"],"correct_index":2,"explanation":"Detection outputs locations and classes."}
{"type":"true_false","question":"IoU measures overlap quality between predicted and ground-truth boxes.","options":["True","False"],"correct_index":0,"explanation":"Intersection over Union ∈ [0,1]."}
{"type":"fill_blank","question":"Pixel-wise labeling of an image is semantic ________.","answer":"segmentation","explanation":"Assigns a class to every pixel."}
{"type":"mcq","question":"If IoU=0.42 and threshold=0.5, the detection is:","options":["TP","FP (or unmatched)","TN","Guaranteed FN"],"correct_index":1,"explanation":"Below threshold → not a TP."}
{"type":"true_false","question":"Data augmentation is applied to training, not validation/test.","options":["True","False"],"correct_index":0,"explanation":"Keep evaluation unbiased."}
{"type":"mcq","question":"mAP aggregates:","options":["Average recall only","Average precision across classes/IoUs","R² across classes","MAE over classes"],"correct_index":1,"explanation":"mAP summarizes detection performance over thresholds."}
{"type":"fill_blank","question":"Adapting ImageNet-pretrained weights to a new task is ________ learning.","answer":"transfer","explanation":"Transfer learning reuses learned representations."}
{"type":"true_false","question":"Aggressive random crops can remove targets, harming detector training.","options":["True","False"],"correct_index":0,"explanation":"Ensure objects remain in view post-crop."}
{"type":"mcq","question":"Which augmentation helps with illumination changes?","options":["Brightness/contrast jitter","Label smoothing","Max pooling","BatchNorm only"],"correct_index":0,"explanation":"Simulates varying lighting conditions."}
{"type":"mcq","question":"If your detector fires on background often, first adjust:","options":["Lower IoU threshold","Raise IoU threshold or add background negatives","Turn off all augmentations","Reduce input size drastically"],"correct_index":1,"explanation":"Tighten matching or provide hard negatives."}
{"type":"true_false","question":"Quantization/pruning can speed up inference on edge devices.","options":["True","False"],"correct_index":0,"explanation":"Compression reduces compute and memory footprint."}
{"type":"mcq","question":"Which metric is best to report for imbalanced positives?","options":["Accuracy only","Precision/Recall/F1/PR-AUC","RMSE","R²"],"correct_index":1,"explanation":"These capture minority class performance better than accuracy."}
{"type":"fill_blank","question":"Using the test set for hyperparameter selection causes optimistic ________.","answer":"bias","explanation":"Overfits to the test set and inflates metrics."}
{"type":"true_false","question":"Grid search is exhaustive; random search samples the space.","options":["True","False"],"correct_index":0,"explanation":"Two common HPO strategies."}
{"type":"mcq","question":"Which reduces variance for a high-variance model?","options":["Bagging/ensembles","Higher LR","Less data","No validation"],"correct_index":0,"explanation":"Averaging decorrelated models stabilizes predictions."}
{"type":"mcq","question":"Which regularization shrinks weights but rarely zeros them exactly?","options":["L1","L2","None","Dropout"],"correct_index":1,"explanation":"L2 (Ridge) discourages large weights without sparsity."}
{"type":"true_false","question":"Standardize features before PCA because PCA is scale-sensitive.","options":["True","False"],"correct_index":0,"explanation":"Unscaled features can dominate PCs."}
{"type":"fill_blank","question":"The area under the ROC curve is abbreviated ________.","answer":"AUC","explanation":"Threshold-independent performance summary."}
{"type":"mcq","question":"Which curve is preferred when positives are rare and you care about positive quality?","options":["ROC","PR curve","Learning curve","Elbow plot"],"correct_index":1,"explanation":"PR focuses on precision/recall trade-offs."}
{"type":"true_false","question":"Lowering the classification threshold generally increases recall.","options":["True","False"],"correct_index":0,"explanation":"More positive predictions → fewer FN."}
{"type":"mcq","question":"Which method combats overfitting in deep nets?","options":["Data augmentation and dropout","Use test for tuning","No validation","Bigger models only"],"correct_index":0,"explanation":"Regularization + more diverse training improve generalization."}
{"type":"mcq","question":"Which post-processing minimizes duplicate detections?","options":["NMS (non-maximum suppression)","Pooling","BatchNorm","Quantization"],"correct_index":0,"explanation":"NMS removes overlapping lower-score boxes."}
{"type":"fill_blank","question":"The F1-score is the harmonic mean of precision and ________.","answer":"recall","explanation":"Balances precision and recall."}
{"type":"true_false","question":"AUC=0.5 implies random ranking performance.","options":["True","False"],"correct_index":0,"explanation":"No better than random guess."}
{"type":"mcq","question":"Which approach handles very high-cardinality categories without exploding columns?","options":["One-hot only","Hashing trick or target/frequency encoding","Manual ranking","Ignore feature"],"correct_index":1,"explanation":"Hashing/target/frequency avoid huge sparse matrices."}
{"type":"mcq","question":"Which sign indicates data leakage?","options":["Train≈Val realistic","Unusually high CV that collapses in production","Stable metrics across folds","Consistent independent test"],"correct_index":1,"explanation":"Leakage inflates validation but fails in real use."}
{"type":"true_false","question":"Label smoothing can improve calibration for neural classifiers.","options":["True","False"],"correct_index":0,"explanation":"Reduces over-confidence in probabilities."}
{"type":"fill_blank","question":"Hyperparameters are settings chosen ________ training.","answer":"before","explanation":"Not learned from data; set a priori or tuned."}
{"type":"mcq","question":"Which cross-validation is fastest but highest variance?","options":["Hold-out","k-fold (k=10)","LOOCV","Stratified k-fold"],"correct_index":0,"explanation":"Single split is quick but unstable."}
{"type":"true_false","question":"Silhouette close to 1 indicates well-separated clusters.","options":["True","False"],"correct_index":0,"explanation":"Values near 1 reflect strong separation vs cohesion."}
{"type":"mcq","question":"Which change usually increases precision but may lower recall?","options":["Lower threshold","Raise threshold","Add noise","Reduce data"],"correct_index":1,"explanation":"Predict positives more cautiously → fewer FP, more FN."}
{"type":"mcq","question":"Which pipeline order avoids leakage?","options":["Scale→Split→Train","Split→Fit scaler on train→Transform→Train","Train→Split→Scale","Split→Fit scaler on all data→Train"],"correct_index":1,"explanation":"Fit transforms on train only, then apply to val/test."}
{"type":"true_false","question":"F1-score equals 1 only if precision and recall are both 1.","options":["True","False"],"correct_index":0,"explanation":"Harmonic mean is maximized only when both are perfect."}
{"type":"fill_blank","question":"Assigning a class distribution that sums to 1 over classes is produced by ________ activation.","answer":"softmax","explanation":"Softmax creates normalized probabilities."}
{"type":"mcq","question":"Which helps small object detection?","options":["Increase input resolution or use feature pyramids","Lower LR only","Remove augmentation","Disable NMS"],"correct_index":0,"explanation":"Higher resolution and multi-scale features improve small-object recall."}
{"type":"true_false","question":"Instance segmentation distinguishes separate objects of the same class.","options":["True","False"],"correct_index":0,"explanation":"Different instances receive distinct masks."}
{"type":"mcq","question":"Which tree hyperparameter guards against tiny over-specialized splits?","options":["min_samples_split","shuffle","random_state","criterion='gini'"],"correct_index":0,"explanation":"Requires a minimum number of samples to split."}
{"type":"mcq","question":"Gradient boosting mainly reduces:","options":["Bias","Variance only","Both always","Data needs"],"correct_index":0,"explanation":"Boosting focuses on correcting residual errors → lowers bias."}
{"type":"true_false","question":"StandardScaler centers features to mean 0 and scales to unit variance.","options":["True","False"],"correct_index":0,"explanation":"Z-score normalization."}
{"type":"fill_blank","question":"K-Means cluster centers are called ________.","answer":"centroids","explanation":"They are the mean of assigned points."}
{"type":"mcq","question":"Which metric would you choose to evaluate a probability ranking of rare positives?","options":["Accuracy","ROC-AUC","PR-AUC","RMSE"],"correct_index":2,"explanation":"PR-AUC focuses on precision/recall under imbalance."}
{"type":"true_false","question":"t-SNE is primarily for visualization of high-dimensional data.","options":["True","False"],"correct_index":0,"explanation":"Produces 2D/3D embeddings for visualization."}
{"type":"mcq","question":"Which coding of nominal categories avoids implying order?","options":["Ordinal mapping","Label encoding","One-hot encoding","Sorting by frequency then labeling"],"correct_index":2,"explanation":"One-hot does not impose rank."}
{"type":"fill_blank","question":"Using validation performance to tune hyperparameters is called ________ search.","answer":"model","explanation":"Grid/random/Bayesian model selection based on validation."}
{"type":"true_false","question":"A perfectly calibrated classifier with p=0.7 will be correct about 70% of the time on such cases.","options":["True","False"],"correct_index":0,"explanation":"That’s calibration by definition."}
{"type":"mcq","question":"Which technique reduces model size for mobile deployment without retraining from scratch?","options":["Quantization aware training only","Post-training quantization or pruning","Add layers","Increase image size"],"correct_index":1,"explanation":"Compression reduces precision/weights to speed inference."}
{"type":"mcq","question":"Which curve plots TPR vs. FPR?","options":["ROC","PR","Learning","Calibration"],"correct_index":0,"explanation":"ROC shows trade-offs across thresholds."}
{"type":"true_false","question":"Lowering threshold increases TP and FP typically.","options":["True","False"],"correct_index":0,"explanation":"More positive predictions increases both TP and FP counts."}
{"type":"fill_blank","question":"Replacing missing values is called ______**.","answer":"imputation","explanation":"E.g., mean/median/KNN imputation."}
{"type":"mcq","question":"Which helps with high-cardinality categorical features?","options":["One-hot only","Hashing or frequency/target encoding","Drop feature always","Arbitrary integer IDs with order"],"correct_index":1,"explanation":"Compact encodings prevent dimensional explosion."}
{"type":"true_false","question":"Silhouette of ~0 suggests overlapping clusters.","options":["True","False"],"correct_index":0,"explanation":"Low values mean poor separation."}
{"type":"mcq","question":"Which indicates high variance (overfitting) in learning curves?","options":["Train↑ Val↓","Train↓ Val↓","Train≈Val high","Train≈Val low"],"correct_index":0,"explanation":"Large gap indicates overfitting."}
{"type":"fill_blank","question":"The process of iteratively improving features from raw inputs is ________ engineering.","answer":"feature","explanation":"Feature engineering improves signal for learning."}
{"type":"true_false","question":"Random Forest benefits little from feature scaling compared to KNN.","options":["True","False"],"correct_index":0,"explanation":"Tree-based models are scale-invariant; KNN is not."}
{"type":"mcq","question":"Which metric is sensitive to class imbalance and focuses on positives?","options":["Accuracy","PR-AUC","RMSE","R²"],"correct_index":1,"explanation":"PR-AUC is informative when positives are rare."}
{"type":"mcq","question":"Which is a proper cross-validation practice?","options":["Tune on test set","Fit preprocessing within each CV fold","Scale on full data before CV","Shuffle labels to test leakage"],"correct_index":1,"explanation":"Preprocessing must be fit on training folds only."}
{"type":"true_false","question":"F1-score penalizes imbalanced precision and recall more than arithmetic mean.","options":["True","False"],"correct_index":0,"explanation":"Harmonic mean emphasizes the smaller value strongly."}
{"type":"fill_blank","question":"Non-maximum ________ removes overlapping lower-score boxes in detection.","answer":"suppression","explanation":"NMS retains the best box per object."}
{"type":"mcq","question":"Which augmentation likely harms digit classification most?","options":["Small rotation","Horizontal flip of digits","Brightness jitter","Minor blur"],"correct_index":1,"explanation":"Flipping digits can change meaning (e.g., 6 vs 9)."}
{"type":"true_false","question":"Boosting reduces bias by sequentially correcting errors.","options":["True","False"],"correct_index":0,"explanation":"Each weak learner focuses on prior residuals."}
{"type":"mcq","question":"Which regularization encourages sparsity (feature selection)?","options":["L1","L2","Dropout only","No penalty"],"correct_index":0,"explanation":"L1 can drive some weights to zero."}
{"type":"fill_blank","question":"The ratio (TP+TN)/All samples is called ********.","answer":"accuracy","explanation":"Fraction of correct predictions."}
{"type":"true_false","question":"Standardizing features usually benefits distance-based models.","options":["True","False"],"correct_index":0,"explanation":"Prevents any feature from dominating distance."}
{"type":"mcq","question":"Which step should be done FIRST in an ML project?","options":["Deploy model","Hyperparameter search","Understand problem and data","Optimize GPU kernels"],"correct_index":2,"explanation":"Problem framing and data understanding precede modeling."}
{"type":"mcq","question":"Which is a valid reason to prefer PR over ROC?","options":["Balanced classes","Rare positives and interest in positive quality","You want TPR vs. FPR explicitly","Binary regression"],"correct_index":1,"explanation":"PR is more informative under class imbalance."}
{"type":"true_false","question":"Calibrated probabilities should match observed frequencies.","options":["True","False"],"correct_index":0,"explanation":"Calibration ensures p≈empirical success rate."}
{"type":"fill_blank","question":"The scikit-learn function to split data is train**********().","answer":"test_split","explanation":"From sklearn.model_selection import train_test_split."}
{"type":"mcq","question":"Which practice best prevents leakage?","options":["Scale before split","Fit transforms on train only","Peek at test for tuning","Use test for early stopping"],"correct_index":1,"explanation":"Estimate statistics on training data only."}
{"type":"true_false","question":"With SAME padding and stride 1, a 3×3 conv keeps H×W unchanged.","options":["True","False"],"correct_index":0,"explanation":"Padding compensates for kernel size."}
{"type":"mcq","question":"Which component primarily introduces nonlinearity in NNs?","options":["Weights","Biases","Activation functions","Loss function"],"correct_index":2,"explanation":"Nonlinear activations enable complex function approximation."}
{"type":"fill_blank","question":"Reducing LR when a metric plateaus is LR ________.","answer":"scheduling","explanation":"Schedulers adjust step size during training."}
{"type":"true_false","question":"PR-AUC focuses on positive class quality; ROC-AUC on ranking overall.","options":["True","False"],"correct_index":0,"explanation":"ROC considers TPR/FPR; PR emphasizes precision/recall."}
{"type":"mcq","question":"Which deployment tactic can reduce latency?","options":["Quantization/pruning","Add layers","Increase input size","Eliminate batching"],"correct_index":0,"explanation":"Compression reduces compute and speeds inference."}
{"type":"mcq","question":"Which is the BEST immediate fix for a huge train–test gap (99% vs 60%)?","options":["More regularization/augmentation","Larger model","Lower batch size only","Less data"],"correct_index":0,"explanation":"Overfitting → add regularization and diversify data."}
{"type":"true_false","question":"Hashing trick maps categories to a fixed number of bins, allowing collisions.","options":["True","False"],"correct_index":0,"explanation":"Collisions are acceptable trade-offs for compactness."}
{"type":"fill_blank","question":"K-Means objective minimizes within-cluster ________.","answer":"inertia","explanation":"Sum of squared distances to centroids."}
{"type":"mcq","question":"Which method visualizes which pixels influenced a CNN decision?","options":["Grad-CAM","ROC curve","Silhouette plot","Elbow method"],"correct_index":0,"explanation":"Grad-CAM produces class-activation heatmaps."}
{"type":"true_false","question":"One should stratify classification splits to preserve class ratios.","options":["True","False"],"correct_index":0,"explanation":"Ensures proportional representation across splits."}
{"type":"mcq","question":"Which combination is appropriate for heavily imbalanced data?","options":["Accuracy only","Class weights, resampling, PR-AUC","Drop minority class","Use FPR alone"],"correct_index":1,"explanation":"Rebalancing and suitable metrics address imbalance."}
{"type":"fill_blank","question":"Assigning probabilities that sum to 1 over classes uses ________ output.","answer":"softmax","explanation":"Softmax converts logits to normalized probabilities."}
{"type":"true_false","question":"Feature engineering and preprocessing are learned from the training set to avoid leakage.","options":["True","False"],"correct_index":0,"explanation":"All statistics should come from training data."}
{"type":"mcq","question":"Which CV has the lowest bias but can be expensive?","options":["LOOCV","Hold-out","k-fold (k=5)","Random split once"],"correct_index":0,"explanation":"LOOCV trains n times with n−1 samples each; low bias, high cost."}
{"type":"mcq","question":"Which measure checks probability calibration quality?","options":["Brier score","RMSE","R²","MSE of labels"],"correct_index":0,"explanation":"Brier measures mean squared error of probabilistic predictions."}
{"type":"true_false","question":"F1-score improves only if both precision and recall improve or one improves significantly without the other dropping much.","options":["True","False"],"correct_index":0,"explanation":"Harmonic mean penalizes imbalance strongly."}
{"type":"fill_blank","question":"Distance-based models rely on comparable ________ scales across features.","answer":"feature","explanation":"Scale features to avoid dominance by large-magnitude variables."}
{"type":"mcq","question":"Which encoder inflates dimensionality most for nominal variables?","options":["One-hot","Hashing","Target encoding","Frequency encoding"],"correct_index":0,"explanation":"One-hot creates a column per category."}
{"type":"true_false","question":"StandardScaler is sensitive to outliers; RobustScaler is less so.","options":["True","False"],"correct_index":0,"explanation":"RobustScaler uses median and IQR."}
{"type":"mcq","question":"Which is a typical semantic segmentation model?","options":["U-Net","YOLOv3 classifier head","LinearRegression","Naive Bayes"],"correct_index":0,"explanation":"U-Net is designed for pixel-level labeling."}
{"type":"fill_blank","question":"Boxes with IoU less than threshold are considered non-matches (often ________).","answer":"FP","explanation":"Below IoU threshold means not a true positive match."}
{"type":"true_false","question":"Random Forests are inherently parallelizable across trees.","options":["True","False"],"correct_index":0,"explanation":"Trees are trained independently on bootstraps."}
{"type":"mcq","question":"Which scenario calls for higher recall than precision?","options":["Spam blocking to avoid false blocks","Cancer screening to avoid missed positives","Email marketing relevance","Image deduplication for UI neatness"],"correct_index":1,"explanation":"Minimize false negatives even if more false positives occur."}
{"type":"mcq","question":"Which technique summarizes duplicate detections in object detection outputs?","options":["NMS","Pooling","BatchNorm","Dropout"],"correct_index":0,"explanation":"NMS keeps highest-scoring box per object."}
{"type":"true_false","question":"Balanced accuracy averages recall over classes and is useful for imbalance.","options":["True","False"],"correct_index":0,"explanation":"Balances contributions from each class."}
{"type":"fill_blank","question":"A model setting such as max_depth or learning_rate is a ________.","answer":"hyperparameter","explanation":"Chosen before/around training, not learned directly."}
{"type":"mcq","question":"Which distance is most common in K-Means?","options":["Hamming","Cosine","Euclidean","Jaccard"],"correct_index":2,"explanation":"K-Means minimizes squared Euclidean distances."}
{"type":"true_false","question":"PCA can speed up clustering by reducing dimensions.","options":["True","False"],"correct_index":0,"explanation":"Lower-dimensional space yields faster distance computations."}
{"type":"mcq","question":"Which indicator suggests K-Means chose too many clusters?","options":["A cluster with just one point far away","High silhouette","Consistent cluster sizes","Stable inertia plateau"],"correct_index":0,"explanation":"Singleton clusters often signal excessive k."}
{"type":"fill_blank","question":"For binary logistic regression, the link function is the ________ function.","answer":"sigmoid","explanation":"Maps linear logits to (0,1) probabilities."}
{"type":"true_false","question":"Adam combines momentum and RMS-like adaptive rates.","options":["True","False"],"correct_index":0,"explanation":"Adam uses estimates of first and second moments."}
{"type":"mcq","question":"Which is an effective regularizer for deep nets besides dropout?","options":["Weight decay (L2)","Higher threshold","Use test for early stopping","No augmentation"],"correct_index":0,"explanation":"L2 discourages large weights and overfitting."}
{"type":"mcq","question":"Which measure is threshold-independent and reflects ranking quality?","options":["AUC-ROC","Precision","Recall","F1-score"],"correct_index":0,"explanation":"AUC-ROC integrates performance across thresholds."}
{"type":"true_false","question":"R² can be negative when model does worse than predicting the mean.","options":["True","False"],"correct_index":0,"explanation":"Poor regression can yield R²<0."}
{"type":"fill_blank","question":"Selecting k by plotting inertia vs. k and finding the ‘knee’ is the ________ method.","answer":"elbow","explanation":"Look for diminishing return point."}
{"type":"mcq","question":"Which practice ensures fair final evaluation?","options":["Tune on test","Use a held-out test set once at the end","Tune loss to match test distribution using test set","Select hyperparameters by test AUC"],"correct_index":1,"explanation":"Keep test untouched until final check."}
{"type":"true_false","question":"Pooling improves some translation invariance in CNNs.","options":["True","False"],"correct_index":0,"explanation":"Aggregates local features reducing sensitivity to small shifts."}
{"type":"mcq","question":"Which is BEST to handle illumination variance in images?","options":["Brightness/contrast jitter","Flip text horizontally","Crop tightly always","Downscale only"],"correct_index":0,"explanation":"Photometric augmentations simulate lighting changes."}
{"type":"fill_blank","question":"The product serving predictions from a model is an inference ________.","answer":"service","explanation":"Often an API endpoint or microservice."}
